{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMGN51DE3ZZg"
   },
   "source": [
    "# To do: \n",
    "- build Ball Tree for cosine similarity\n",
    "- implement Bayesian optimisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c1pxoCjT4CbP",
    "outputId": "64daf71e-046a-485a-9cc9-8e781543e577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-22 07:07:14--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
      "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
      "--2020-08-22 07:07:14--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 93052469 (89M) [application/x-sh]\n",
      "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
      "\n",
      "\r",
      "          Miniconda   0%[                    ]       0  --.-KB/s               \r",
      "         Miniconda3  59%[==========>         ]  52.87M   264MB/s               \r",
      "Miniconda3-latest-L 100%[===================>]  88.74M   293MB/s    in 0.3s    \n",
      "\n",
      "2020-08-22 07:07:14 (293 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [93052469/93052469]\n",
      "\n",
      "PREFIX=/usr/local\n",
      "Unpacking payload ...\n",
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
      "Solving environment: - \b\b\\ \b\bdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs:\n",
      "    - _libgcc_mutex==0.1=main\n",
      "    - ca-certificates==2020.1.1=0\n",
      "    - certifi==2020.4.5.1=py38_0\n",
      "    - cffi==1.14.0=py38he30daa8_1\n",
      "    - chardet==3.0.4=py38_1003\n",
      "    - conda-package-handling==1.6.1=py38h7b6447c_0\n",
      "    - conda==4.8.3=py38_0\n",
      "    - cryptography==2.9.2=py38h1ba5d50_0\n",
      "    - idna==2.9=py_1\n",
      "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
      "    - libedit==3.1.20181209=hc058e9b_0\n",
      "    - libffi==3.3=he6710b0_1\n",
      "    - libgcc-ng==9.1.0=hdf63c60_0\n",
      "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
      "    - ncurses==6.2=he6710b0_1\n",
      "    - openssl==1.1.1g=h7b6447c_0\n",
      "    - pip==20.0.2=py38_3\n",
      "    - pycosat==0.6.3=py38h7b6447c_1\n",
      "    - pycparser==2.20=py_0\n",
      "    - pyopenssl==19.1.0=py38_0\n",
      "    - pysocks==1.7.1=py38_0\n",
      "    - python==3.8.3=hcff3b4d_0\n",
      "    - readline==8.0=h7b6447c_0\n",
      "    - requests==2.23.0=py38_0\n",
      "    - ruamel_yaml==0.15.87=py38h7b6447c_0\n",
      "    - setuptools==46.4.0=py38_0\n",
      "    - six==1.14.0=py38_0\n",
      "    - sqlite==3.31.1=h62c20be_1\n",
      "    - tk==8.6.8=hbc83047_0\n",
      "    - tqdm==4.46.0=py_0\n",
      "    - urllib3==1.25.8=py38_0\n",
      "    - wheel==0.34.2=py38_0\n",
      "    - xz==5.2.5=h7b6447c_0\n",
      "    - yaml==0.1.7=had09818_2\n",
      "    - zlib==1.2.11=h7b6447c_3\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
      "  certifi            pkgs/main/linux-64::certifi-2020.4.5.1-py38_0\n",
      "  cffi               pkgs/main/linux-64::cffi-1.14.0-py38he30daa8_1\n",
      "  chardet            pkgs/main/linux-64::chardet-3.0.4-py38_1003\n",
      "  conda              pkgs/main/linux-64::conda-4.8.3-py38_0\n",
      "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.1-py38h7b6447c_0\n",
      "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py38h1ba5d50_0\n",
      "  idna               pkgs/main/noarch::idna-2.9-py_1\n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_1\n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
      "  pip                pkgs/main/linux-64::pip-20.0.2-py38_3\n",
      "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
      "  pycparser          pkgs/main/noarch::pycparser-2.20-py_0\n",
      "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py38_0\n",
      "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38_0\n",
      "  python             pkgs/main/linux-64::python-3.8.3-hcff3b4d_0\n",
      "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
      "  requests           pkgs/main/linux-64::requests-2.23.0-py38_0\n",
      "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py38h7b6447c_0\n",
      "  setuptools         pkgs/main/linux-64::setuptools-46.4.0-py38_0\n",
      "  six                pkgs/main/linux-64::six-1.14.0-py38_0\n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h62c20be_1\n",
      "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
      "  tqdm               pkgs/main/noarch::tqdm-4.46.0-py_0\n",
      "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py38_0\n",
      "  wheel              pkgs/main/linux-64::wheel-0.34.2-py38_0\n",
      "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
      "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
      "\n",
      "\n",
      "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
      "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
      "installation finished.\n",
      "WARNING:\n",
      "    You currently have a PYTHONPATH environment variable set. This may cause\n",
      "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
      "    For best results, please verify that your PYTHONPATH only points to\n",
      "    directories of packages that are compatible with the Python interpreter\n",
      "    in Miniconda3: /usr/local\n",
      "\n",
      "real\t0m29.942s\n",
      "user\t0m12.298s\n",
      "sys\t0m3.655s\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    brotlipy-0.7.0             |py37h8f50634_1000         346 KB  conda-forge\n",
      "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
      "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
      "    cffi-1.14.1                |   py37he30daa8_0         226 KB\n",
      "    chardet-3.0.4              |py37hc8dfbb8_1006         169 KB  conda-forge\n",
      "    conda-4.8.4                |   py37hc8dfbb8_2         3.1 MB  conda-forge\n",
      "    conda-package-handling-1.7.0|   py37h8f50634_4         2.0 MB  conda-forge\n",
      "    cryptography-3.0           |   py37hb09aad4_0         633 KB  conda-forge\n",
      "    openssl-1.1.1g             |       h516909a_1         2.1 MB  conda-forge\n",
      "    pip-20.2.2                 |             py_0         1.1 MB  conda-forge\n",
      "    pycosat-0.6.3              |py37h8f50634_1004         107 KB  conda-forge\n",
      "    pyopenssl-19.1.0           |             py_1          47 KB  conda-forge\n",
      "    pysocks-1.7.1              |   py37hc8dfbb8_1          27 KB  conda-forge\n",
      "    python-3.7.7               |       hcff3b4d_5        45.1 MB\n",
      "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
      "    requests-2.24.0            |     pyh9f0ad1d_0          47 KB  conda-forge\n",
      "    ruamel_yaml-0.15.87        |   py37h7b6447c_0         256 KB\n",
      "    setuptools-49.6.0          |   py37hc8dfbb8_0         948 KB  conda-forge\n",
      "    six-1.15.0                 |     pyh9f0ad1d_0          14 KB  conda-forge\n",
      "    urllib3-1.25.10            |             py_0          92 KB  conda-forge\n",
      "    wheel-0.35.1               |     pyh9f0ad1d_0          29 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        56.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py37h8f50634_1000\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
      "  certifi              pkgs/main::certifi-2020.4.5.1-py38_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0\n",
      "  cffi                                1.14.0-py38he30daa8_1 --> 1.14.1-py37he30daa8_0\n",
      "  chardet                pkgs/main::chardet-3.0.4-py38_1003 --> conda-forge::chardet-3.0.4-py37hc8dfbb8_1006\n",
      "  conda                       pkgs/main::conda-4.8.3-py38_0 --> conda-forge::conda-4.8.4-py37hc8dfbb8_2\n",
      "  conda-package-han~ pkgs/main::conda-package-handling-1.6~ --> conda-forge::conda-package-handling-1.7.0-py37h8f50634_4\n",
      "  cryptography       pkgs/main::cryptography-2.9.2-py38h1b~ --> conda-forge::cryptography-3.0-py37hb09aad4_0\n",
      "  openssl              pkgs/main::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_1\n",
      "  pip                 pkgs/main/linux-64::pip-20.0.2-py38_3 --> conda-forge/noarch::pip-20.2.2-py_0\n",
      "  pycosat            pkgs/main::pycosat-0.6.3-py38h7b6447c~ --> conda-forge::pycosat-0.6.3-py37h8f50634_1004\n",
      "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-~ --> conda-forge/noarch::pyopenssl-19.1.0-py_1\n",
      "  pysocks                   pkgs/main::pysocks-1.7.1-py38_0 --> conda-forge::pysocks-1.7.1-py37hc8dfbb8_1\n",
      "  requests           pkgs/main/linux-64::requests-2.23.0-p~ --> conda-forge/noarch::requests-2.24.0-pyh9f0ad1d_0\n",
      "  setuptools            pkgs/main::setuptools-46.4.0-py38_0 --> conda-forge::setuptools-49.6.0-py37hc8dfbb8_0\n",
      "  six                 pkgs/main/linux-64::six-1.14.0-py38_0 --> conda-forge/noarch::six-1.15.0-pyh9f0ad1d_0\n",
      "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py~ --> conda-forge/noarch::urllib3-1.25.10-py_0\n",
      "  wheel              pkgs/main/linux-64::wheel-0.34.2-py38~ --> conda-forge/noarch::wheel-0.35.1-pyh9f0ad1d_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  python                                   3.8.3-hcff3b4d_0 --> 3.7.7-hcff3b4d_5\n",
      "  ruamel_yaml                        0.15.87-py38h7b6447c_0 --> 0.15.87-py37h7b6447c_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "real\t0m14.569s\n",
      "user\t0m11.758s\n",
      "sys\t0m2.047s\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs:\n",
      "    - rdkit\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
      "    boost-cpp-1.72.0           |       h7b93d67_2        16.3 MB  conda-forge\n",
      "    bzip2-1.0.8                |       h516909a_3         398 KB  conda-forge\n",
      "    cairo-1.16.0               |    h3fc0475_1005         1.5 MB  conda-forge\n",
      "    fontconfig-2.13.1          |    h1056068_1002         365 KB  conda-forge\n",
      "    freetype-2.10.2            |       he06d7ca_0         905 KB  conda-forge\n",
      "    glib-2.65.0                |       h3eb4bd4_0         2.9 MB\n",
      "    icu-67.1                   |       he1b5a44_0        12.9 MB  conda-forge\n",
      "    jpeg-9d                    |       h516909a_0         266 KB  conda-forge\n",
      "    lcms2-2.11                 |       hbd6801e_0         431 KB  conda-forge\n",
      "    libblas-3.8.0              |      17_openblas          11 KB  conda-forge\n",
      "    libcblas-3.8.0             |      17_openblas          11 KB  conda-forge\n",
      "    libgfortran-ng-7.5.0       |      hdf63c60_15         1.3 MB  conda-forge\n",
      "    libiconv-1.16              |       h516909a_0         1.4 MB  conda-forge\n",
      "    liblapack-3.8.0            |      17_openblas          11 KB  conda-forge\n",
      "    libopenblas-0.3.10         |pthreads_hb3c22a3_4         7.8 MB  conda-forge\n",
      "    libpng-1.6.37              |       hed695b0_2         359 KB  conda-forge\n",
      "    libtiff-4.1.0              |       hc7e4089_6         668 KB  conda-forge\n",
      "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
      "    libwebp-base-1.1.0         |       h516909a_3         845 KB  conda-forge\n",
      "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
      "    libxml2-2.9.10             |       h68273f3_2         1.3 MB  conda-forge\n",
      "    lz4-c-1.9.2                |       he1b5a44_3         203 KB  conda-forge\n",
      "    numpy-1.19.1               |   py37h7ea13bd_2         5.2 MB  conda-forge\n",
      "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
      "    pandas-1.1.0               |   py37h3340039_0        10.5 MB  conda-forge\n",
      "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
      "    pillow-7.2.0               |   py37h718be6c_1         675 KB  conda-forge\n",
      "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
      "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
      "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
      "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
      "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
      "    rdkit-2020.03.5            |   py37h3f38cc2_0        24.7 MB  conda-forge\n",
      "    tk-8.6.10                  |       hed695b0_0         3.2 MB  conda-forge\n",
      "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
      "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
      "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
      "    xorg-libx11-1.6.11         |       h516909a_0         920 KB  conda-forge\n",
      "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
      "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
      "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
      "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
      "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
      "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
      "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
      "    zstd-1.4.5                 |       h6597ccf_2         712 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        97.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
      "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h7b93d67_2\n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_3\n",
      "  cairo              conda-forge/linux-64::cairo-1.16.0-h3fc0475_1005\n",
      "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h1056068_1002\n",
      "  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0\n",
      "  glib               pkgs/main/linux-64::glib-2.65.0-h3eb4bd4_0\n",
      "  icu                conda-forge/linux-64::icu-67.1-he1b5a44_0\n",
      "  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0\n",
      "  lcms2              conda-forge/linux-64::lcms2-2.11-hbd6801e_0\n",
      "  libblas            conda-forge/linux-64::libblas-3.8.0-17_openblas\n",
      "  libcblas           conda-forge/linux-64::libcblas-3.8.0-17_openblas\n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_15\n",
      "  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0\n",
      "  liblapack          conda-forge/linux-64::liblapack-3.8.0-17_openblas\n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.10-pthreads_hb3c22a3_4\n",
      "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_2\n",
      "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
      "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3\n",
      "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
      "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h68273f3_2\n",
      "  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_3\n",
      "  numpy              conda-forge/linux-64::numpy-1.19.1-py37h7ea13bd_2\n",
      "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
      "  pandas             conda-forge/linux-64::pandas-1.1.0-py37h3340039_0\n",
      "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
      "  pillow             conda-forge/linux-64::pillow-7.2.0-py37h718be6c_1\n",
      "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
      "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
      "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
      "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
      "  rdkit              conda-forge/linux-64::rdkit-2020.03.5-py37h3f38cc2_0\n",
      "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
      "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
      "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
      "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.11-h516909a_0\n",
      "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
      "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
      "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
      "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
      "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
      "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
      "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
      "  zstd               conda-forge/linux-64::zstd-1.4.5-h6597ccf_2\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  tk                         pkgs/main::tk-8.6.8-hbc83047_0 --> conda-forge::tk-8.6.10-hed695b0_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "real\t0m35.384s\n",
      "user\t0m30.589s\n",
      "sys\t0m3.339s\n"
     ]
    }
   ],
   "source": [
    "# GOOGLE COLAB: Install RDKit. Takes 2-3 minutes \n",
    "# !wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# !chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "# !time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# !time conda install -q -y -c conda-forge python=3.7\n",
    "# !time conda install -q -y -c conda-forge rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "87OYfp5T4QDS",
    "outputId": "75529064-96b2-4865-c0d9-67487da207ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# GOOGLE COLAB\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8Q1rtww36JU"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLAB\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_nomap_noreagent.pickle' '/content/'\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/usr/local/lib/python3.7/site-packages/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSKTT4aD3ZZh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import rdqueries # faster than iterating atoms https://sourceforge.net/p/rdkit/mailman/message/34538007/ \n",
    "from rdkit.Chem.rdchem import Atom\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re \n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MINCF8E3ZZk"
   },
   "source": [
    "### References for papers using fingerprints as inputs\n",
    "https://pubs.acs.org/doi/pdf/10.1021/acscentsci.6b00219 and https://github.com/jnwei/neural_reaction_fingerprint\n",
    "http://pubs.acs.org.remotexs.ntu.edu.sg/doi/pdf/10.1021/ci5006614 (IPython notebooks in Supplementary Info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFZp1L1r3ZZl"
   },
   "source": [
    "### MorganFP not fixed values? why results not static? magnitude is big. do we need some form of scaling?? need to look into dtype also.  \n",
    "- int gives scarily big numbers\n",
    "- need to use int8 with large enough fp_size (e.g. 16384, which was used by <u>Reaction Condition Recommender ACS Cent. Sci. 2018, 4, 1465−1476</u>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU0QoD8e3ZZm",
    "outputId": "0ae96e8d-8718-4a8d-ea09-078b9339745e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print(create_rxn_MorganFP(sample_rxns[0], fp_size=16384)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfF81_7d3ZZp",
    "outputId": "bdd4c5da-91d7-4275-c180-bb6a2aa65576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196411728       370 325594256       370         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0]\n"
     ]
    }
   ],
   "source": [
    "# print(create_rxn_MorganFP(sample_rxns[0], fp_size=16384, dtype='int')[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMIpqIVk3ZZs"
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfFuy7g03ZZs"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_activation_function(activation: str) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Gets an activation function module given the name of the activation.\n",
    "    Supports:\n",
    "    * :code:`ReLU`\n",
    "    * :code:`LeakyReLU`\n",
    "    * :code:`PReLU`\n",
    "    * :code:`tanh`\n",
    "    * :code:`SELU`\n",
    "    * :code:`ELU`\n",
    "    :param activation: The name of the activation function.\n",
    "    :return: The activation function module.\n",
    "    \"\"\"\n",
    "    if activation == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'LeakyReLU':\n",
    "        return nn.LeakyReLU(0.1)\n",
    "    elif activation == 'PReLU':\n",
    "        return nn.PReLU()\n",
    "    elif activation == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif activation == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif activation == 'ELU':\n",
    "        return nn.ELU()\n",
    "    else:\n",
    "        raise ValueError(f'Activation \"{activation}\" not supported.')\n",
    "    \n",
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Initializes the weights of a model in place.\n",
    "    :param model: An PyTorch model.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant_(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1Cfy0AF3ZZv"
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxvJUWjr3ZZw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FF_ebm(nn.Module):\n",
    "    '''\n",
    "    trainargs: dictionary containing hyperparameters to be optimised, \n",
    "    hidden_sizes must be a list e.g. [1024, 512, 256]\n",
    "    \n",
    "    To do: bayesian optimisation\n",
    "    '''\n",
    "    def __init__(self, trainargs):\n",
    "        super(FF_ebm, self).__init__()\n",
    "        self.output_size = trainargs['output_size']\n",
    "        self.num_layers = len(trainargs['hidden_sizes']) + 1\n",
    "\n",
    "        if trainargs['model'] == 'FF_sep':\n",
    "          self.input_dim = trainargs['rctfp_size'] + trainargs['prodfp_size']\n",
    "        elif trainargs['model'] == 'FF_diff':\n",
    "          self.input_dim = trainargs['fp_size']\n",
    "\n",
    "        self.create_ffn(trainargs)\n",
    "        initialize_weights(self)\n",
    "    \n",
    "    def create_ffn(self, trainargs):\n",
    "        '''\n",
    "        Creates feed-forward network using trainargs dict\n",
    "        '''\n",
    "        dropout = nn.Dropout(trainargs['dropout'])\n",
    "        activation = get_activation_function(trainargs['activation'])\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, self.output_size)\n",
    "            ]\n",
    "        else:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, trainargs['hidden_sizes'][0])\n",
    "            ]\n",
    "            \n",
    "            # intermediate hidden layers \n",
    "            for i, layer in enumerate(range(self.num_layers - 2)):\n",
    "                ffn.extend([\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    nn.Linear(trainargs['hidden_sizes'][i], trainargs['hidden_sizes'][i+1]),\n",
    "                ])\n",
    "                \n",
    "            # last hidden layer\n",
    "            ffn.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(trainargs['hidden_sizes'][-1], self.output_size),\n",
    "            ])\n",
    "\n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        '''\n",
    "        Runs FF_ebm on input\n",
    "        \n",
    "        batch: a N x K x 1 tensor of N training samples, where each sample contains \n",
    "        a positive rxn on the first column, and K-1 negative rxn on subsequent columns \n",
    "        supplied by DataLoader on custom ReactionDataset \n",
    "        '''\n",
    "        energy_scores = self.ffn(batch) # tensor of size N x K x 1\n",
    "        return energy_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7EzzESW3ZZz"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeAWhxLw3ZZz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "def train_one(model, batch, optimizer, val=False):\n",
    "    '''\n",
    "    Trains model for 1 epoch \n",
    "    \n",
    "    TO DO: learning rate scheduler + logger \n",
    "    '''\n",
    "    model.zero_grad()\n",
    "    scores = model.forward(batch).squeeze(dim=-1) # scores: size N x K x 1 --> N x K after squeezing\n",
    "    \n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    probs = softmax(scores) # size N x K\n",
    "    \n",
    "    # positives are the 0-th index of each sample, add a small epsilon 1e-9 to stabilise log \n",
    "    loss = -torch.log(probs[:, 0]+1e-9).mean() # probs[:, 0] is size N x 1 --> sum/mean to 1 value\n",
    "    \n",
    "    if not val:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    #     if args.grad_clip: # gradient clipping if needed \n",
    "    #         nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.data.cpu()\n",
    "    \n",
    "def train(model, trainargs):\n",
    "    '''\n",
    "    Trains model for num_epochs provided in trainargs\n",
    "    Currently supports feed-forward networks: \n",
    "        FF_diff: takes as input a difference FP of fp_size & fp_radius\n",
    "        FF_sep: takes as input a concatenation of [reactants FP, product FP] \n",
    "    \n",
    "    trainargs: dict of params \n",
    "    '''\n",
    "    start = time.time()\n",
    "    stats = {'trainargs': trainargs} # to store training statistics \n",
    "    torch.manual_seed(trainargs['model_seed'])\n",
    "    random.seed(trainargs['random_seed'])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    optimizer = trainargs['optimizer'](model.parameters(), lr=trainargs['learning_rate'])\n",
    "    \n",
    "    train_dataset = ReactionDataset(trainargs['path_to_pickle'], 'train', trainargs)\n",
    "    train_loader = DataLoader(train_dataset, trainargs['batch_size'], shuffle=True)\n",
    "    mean_train_loss = []\n",
    "    \n",
    "    val_dataset = ReactionDataset(trainargs['path_to_pickle'], 'valid', trainargs)\n",
    "    val_loader = DataLoader(val_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "    min_val_loss = 1e9\n",
    "    mean_val_loss = []\n",
    "    \n",
    "    for epoch in np.arange(trainargs['epochs']):\n",
    "        model.train() # set model to training mode\n",
    "        train_loss = []\n",
    "        for batch in tqdm(train_loader): \n",
    "            batch = batch.to(device)\n",
    "            train_loss.append(train_one(model, batch, optimizer, val=False))\n",
    "            mean_train_loss.append(np.mean(train_loss)) \n",
    "            # print('train_loss: {}'.format(train_loss))\n",
    "        \n",
    "        model.eval() # validation mode\n",
    "        val_loss = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                batch = batch.to(device)\n",
    "                val_loss.append(train_one(model, batch, optimizer, val=True))\n",
    "        \n",
    "            if trainargs['early_stop'] and min_val_loss - np.mean(val_loss) < trainargs['min_delta']:\n",
    "                if trainargs['patience'] <= wait:\n",
    "                    print('Early stopped at the end of epoch: ', epoch)\n",
    "                    stats['early_stop_epoch'] = epoch \n",
    "                    break \n",
    "                else:\n",
    "                    wait += 1\n",
    "                    print('Decrease in val loss < min_delta, patience count: ', wait)\n",
    "            else:\n",
    "                wait = 0\n",
    "                min_val_loss = min(min_val_loss, np.mean(val_loss))\n",
    "            mean_val_loss.append(np.mean(val_loss))\n",
    "        \n",
    "        if trainargs['checkpoint']: # adapted from moco: main_moco.py\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model': trainargs['model'],\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                    'stats' : stats,\n",
    "                }, is_best=False, filename=trainargs['checkpoint_path']+'{}_{}_checkpoint_{:04d}.pth.tar'.format(trainargs['model'], trainargs['expt_name'], epoch))\n",
    "        \n",
    "        print('Epoch: {}, train_loss: {}, val_loss: {}'.format(epoch, \n",
    "                                         np.around(np.mean(train_loss), decimals=4), \n",
    "                                         np.around(np.mean(val_loss), decimals=4)))\n",
    "      \n",
    "    stats['mean_train_loss'] = mean_train_loss\n",
    "    stats['mean_val_loss'] = mean_val_loss\n",
    "    stats['min_val_loss'] = min_val_loss\n",
    "    stats['train_time'] = time.time() - start \n",
    "    # save training stats\n",
    "    torch.save(stats, trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(trainargs['model'], trainargs['expt_name']))\n",
    "    return stats \n",
    "              \n",
    "def test(model, stats, trainargs):\n",
    "    '''\n",
    "    Evaluates the model on the test set \n",
    "    '''\n",
    "    test_dataset = ReactionDataset(trainargs['path_to_pickle'], 'test', trainargs)\n",
    "    test_loader = DataLoader(test_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            test_loss.append(train_one(model, batch, optimizer, val=True))\n",
    "              \n",
    "    stats['test_loss'] = test_loss \n",
    "    stats['mean_test_loss'] = np.mean(test_loss)\n",
    "    print('train_time: {}'.format(stats['train_time']))\n",
    "    print('test_loss: {:.4f}'.format(stats['test_loss']))\n",
    "    # overrides training stats w/ training + test stats\n",
    "    torch.save(stats, trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(trainargs['model'], trainargs['expt_name'])) \n",
    "    return stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o12DGGe3ZZ2"
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYdV62U63ZZ3"
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/tutorials/blob/master/beginner_source/data_loading_tutorial.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def create_rxn_MorganFP(rxn_smi, fp_type='diff', radius=2, rctfp_size=16384, prodfp_size=16384, useChirality=True, dtype='int8'):\n",
    "    '''\n",
    "    fp_type: 'diff' or 'sep', \n",
    "    'diff' (difference):\n",
    "    Creates reaction MorganFP following Schneider et al in J. Chem. Inf. Model. 2015, 55, 1, 39–53\n",
    "    reactionFP = productFP - sum(reactantFPs)\n",
    "    \n",
    "    'sep' (separate):\n",
    "    Creates separate reactantsFP and productFP following Gao et al in ACS Cent. Sci. 2018, 4, 11, 1465–1476\n",
    "    '''\n",
    "    # initialise empty fp numpy arrays\n",
    "    if fp_type == 'diff':\n",
    "        diff_fp = np.empty(fp_size, dtype = dtype)\n",
    "    elif fp_type == 'sep':\n",
    "        rcts_fp = np.empty(rctfp_size, dtype = dtype)\n",
    "        prod_fp = np.empty(prodfp_size, dtype = dtype)\n",
    "    else:\n",
    "        print('ERROR: fp_type not recognised!')\n",
    "        return\n",
    "    \n",
    "    # create product FP\n",
    "    prod_mol = Chem.MolFromSmiles(rxn_smi.split('>')[-1])\n",
    "    try:\n",
    "        prod_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                        mol=prod_mol, radius=radius, nBits=prodfp_size, useChirality=useChirality)\n",
    "\n",
    "        fp = np.empty(prodfp_size, dtype = dtype)   # temporarily store numpy array as fp \n",
    "        DataStructs.ConvertToNumpyArray(prod_fp_bit, fp)\n",
    "        if fp_type == 'diff':\n",
    "            diff_fp += fp\n",
    "        elif fp_type == 'sep':\n",
    "            prod_fp = fp\n",
    "    except Exception as e:\n",
    "        print(\"Cannot build product fp due to {}\".format(e))\n",
    "        return\n",
    "                                  \n",
    "    # create reactant FPs, subtracting each from product FP\n",
    "    rcts_smi = rxn_smi.split('>')[0].split('.')\n",
    "    for rct_smi in rcts_smi:\n",
    "        rct_mol = Chem.MolFromSmiles(rct_smi)\n",
    "        try:\n",
    "            rct_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                            mol=rct_mol, radius=radius, nBits=rctfp_size, useChirality=useChirality)\n",
    "            fp = np.empty(rctfp_size, dtype = dtype)\n",
    "            DataStructs.ConvertToNumpyArray(rct_fp_bit, fp)\n",
    "            if fp_type == 'diff':\n",
    "                diff_fp -= fp\n",
    "            elif fp_type == 'sep':\n",
    "                rcts_fp += fp\n",
    "        except Exception as e:\n",
    "            print(\"Cannot build reactant fp due to {}\".format(e))\n",
    "            return\n",
    "    \n",
    "    if fp_type == 'diff':\n",
    "        return diff_fp\n",
    "    elif fp_type == 'sep':\n",
    "        return np.concatenate([rcts_fp, prod_fp])\n",
    "\n",
    "    \n",
    "class ReactionDataset(Dataset):\n",
    "    '''\n",
    "    The Dataset class ReactionDataset prepares training samples of length K: \n",
    "    [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1], ... where K-1 = num_neg \n",
    "\n",
    "    TO DO: can this be further optimised? Augmentation is the clear bottleneck during training\n",
    "    '''\n",
    "    def __init__(self, path_to_pickle, key, trainargs):\n",
    "        '''\n",
    "        pickle is dict w/ keys 'train', 'valid', 'test' each storing a list of rxn_smiles (str)\n",
    "        IMPORTANT: molAtomMapNumbers have been cleared during data pre-processing \n",
    "        ''' \n",
    "        # feels like loading the entire pickle is not feasible when the dataset gets larger \n",
    "        # is there a more memory-efficient way to do this? \n",
    "        with open(path_to_pickle, 'rb') as handle: \n",
    "            self.rxn_smiles = pickle.load(handle)[key] \n",
    "        self.fp_radius = trainargs['fp_radius']\n",
    "        self.rctfp_size = trainargs['rctfp_size']\n",
    "        self.prodfp_size = trainargs['prodfp_size']\n",
    "        self.fp_type = trainargs['fp_type']\n",
    "        self.num_neg = trainargs['num_neg']\n",
    "    \n",
    "    def random_sample_negative(self, pos_rxn_smi, pos_rxn_idx):\n",
    "        '''\n",
    "        Generates 1 negative reaction given a positive reaction SMILES\n",
    "        Returns neg_rxn_smi (str)\n",
    "        '''\n",
    "        rcts_smi = pos_rxn_smi.split('>')[0].split('.')\n",
    "        prod_smi = pos_rxn_smi.split('>')[-1]       \n",
    "            \n",
    "        rct_or_prod = random.choice([0, 1])\n",
    "        if rct_or_prod == 0: # randomly change one of the reactant(s)\n",
    "            orig_idx = random.choice(np.arange(len(rcts_smi))) # randomly choose 1 reactant to be replaced\n",
    "            \n",
    "            found = False\n",
    "            while not found: # searches randomly to find a different rct molecule to swap with \n",
    "                rdm_rxn_idx = random.choice(np.arange(len(self.rxn_smiles))) # randomly choose 1 rxn\n",
    "                if rdm_rxn_idx == pos_rxn_idx: continue # don't choose the original rxn\n",
    "                        \n",
    "                new_rxn_smi = self.rxn_smiles[rdm_rxn_idx]\n",
    "                new_rcts_smi = new_rxn_smi.split('>')[0].split('.')\n",
    "\n",
    "                rdm_rcts_idx = random.choice(np.arange(len(new_rcts_smi)))\n",
    "                if new_rcts_smi[rdm_rcts_idx] != rcts_smi[orig_idx]:\n",
    "                    found = True\n",
    "                    rcts_smi[orig_idx] = new_rcts_smi[rdm_rcts_idx]\n",
    "            \n",
    "        else: # randomly change the product            \n",
    "            found = False\n",
    "            while not found:  # searches randomly to find a different prod molecule to swap with \n",
    "                rdm_rxn_idx = random.choice(np.arange(len(self.rxn_smiles)))\n",
    "                if rdm_rxn_idx == pos_rxn_idx: continue # don't choose the original rxn\n",
    "                        \n",
    "                new_rxn_smi = self.rxn_smiles[rdm_rxn_idx]      \n",
    "                new_prod_smi = new_rxn_smi.split('>')[-1]\n",
    "                if new_prod_smi != prod_smi:\n",
    "                    found = True\n",
    "                    prod_smi = new_prod_smi\n",
    "        \n",
    "        return '{}>>{}'.format('.'.join(rcts_smi), prod_smi)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ''' \n",
    "        Returns 1 training sample in the form [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1]\n",
    "        num_neg: a hyperparameter to be tuned\n",
    "        \n",
    "        MAY DO: use while loops to retrieve MorganFP in case some of them fail (but this dataset is cleaned already)\n",
    "        '''\n",
    "        if torch.is_tensor(idx): # may not be needed, taken from data loading tutorial\n",
    "            idx = idx.tolist() \n",
    "        \n",
    "        pos_rxn_smi = self.rxn_smiles[idx]\n",
    "        pos_rxn_fp = create_rxn_MorganFP(pos_rxn_smi, radius=self.fp_radius, \n",
    "                                         rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n",
    "        \n",
    "        assert self.num_neg > 0, 'num_neg cannot be negative!'\n",
    "        neg_rxn_smis = [self.random_sample_negative(pos_rxn_smi, idx) for i in range(self.num_neg)]\n",
    "        neg_rxn_fps = [create_rxn_MorganFP(neg_rxn_smi, radius=self.fp_radius,  \n",
    "                                           rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n",
    "                      for neg_rxn_smi in neg_rxn_smis]\n",
    "        \n",
    "        return torch.Tensor([pos_rxn_fp, *neg_rxn_fps])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rxn_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twEVWkj63ZZ5"
   },
   "source": [
    "### Preliminary checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjffU9Uk3ZZ5"
   },
   "outputs": [],
   "source": [
    "trainargs = {\n",
    "    'model': 'FF_sep',\n",
    "    'hidden_sizes': [512],  \n",
    "    'output_size': 1,\n",
    "    'dropout': 0.5, # adapted from Reaction Condition Recommender   \n",
    "    \n",
    "    'batch_size': 256,\n",
    "    'activation': 'ELU', # trying ELU for its differentiability everywhere (vs ReLU which is not differentiable at x=0)\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 1e-6, # to try: integrate w/ fast.ai lr_finder & lr_schedulers \n",
    "    'epochs': 50,\n",
    "    'early_stop': True,\n",
    "    'min_delta': 1e-5, \n",
    "    'patience': 5,\n",
    "\n",
    "    'checkpoint': True,\n",
    "    'model_seed': 1337,\n",
    "    'random_seed': 0, # affects neg rxn sampling since it is random\n",
    "    \n",
    "    'rctfp_size': 16384,\n",
    "    'prodfp_size': 16384,\n",
    "    'fp_radius': 3,\n",
    "    'fp_type': 'sep',\n",
    "    \n",
    "    'num_neg': 9, # to be tuned, 9 seems to be superior to 5 (overfitting occured quickly)\n",
    "    \n",
    "    'path_to_pickle': os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle', \n",
    "    'checkpoint_path': os.getcwd()+'/checkpoints/',\n",
    "    'expt_name': '1layer_rad3_ELU'\n",
    "}\n",
    "\n",
    "train_dataset = ReactionDataset(os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle',\n",
    "                               'train',\n",
    "                               trainargs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FF_ebm(trainargs)\n",
    "model.to(device)\n",
    "train_loader = DataLoader(train_dataset, trainargs['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "-Q2oD8zk3ZZ8",
    "outputId": "886362d3-f8f0-49ef-bbb6-d70355ea5c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 6, 32768]) torch.Size([256, 6, 1])\n",
      "1 torch.Size([256, 6, 32768]) torch.Size([256, 6, 1])\n",
      "2 torch.Size([256, 6, 32768]) torch.Size([256, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched = sample_batched.to(device)\n",
    "    i_scores = model.forward(sample_batched)\n",
    "    print(i_batch, sample_batched.shape, i_scores.shape)\n",
    "\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "l861SYYo3ZZ-",
    "outputId": "c2e69f32-45ec-478f-b8f8-f8789edf1436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.3954, device='cuda:0', grad_fn=<NegBackward>), torch.Size([256]))"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = i_scores.squeeze(dim=-1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "probs = softmax(scores) # size N x K\n",
    "\n",
    "# positives are the 0-th index of each sample \n",
    "loss = -torch.log(probs[:, 0]).mean() # probs[:, 0] is size N x 1 --> sum to 1 value\n",
    "loss, probs[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "evHcirGbGZUL",
    "outputId": "ad0d59da-4298-465a-c168-6f425460239f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3954)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ti5ndWB3ZaA"
   },
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "890bgQ783ZaB"
   },
   "outputs": [],
   "source": [
    "trainargs = {\n",
    "    'model': 'FF_sep',\n",
    "    'hidden_sizes': [512],  \n",
    "    'output_size': 1,\n",
    "    'dropout': 0.5, # adapted from Reaction Condition Recommender   \n",
    "    \n",
    "    'batch_size': 256,\n",
    "    'activation': 'ELU', # trying ELU for its differentiability everywhere (vs ReLU which is not differentiable at x=0)\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 1e-6, # to try: integrate w/ fast.ai lr_finder & lr_schedulers \n",
    "    'epochs': 50,\n",
    "    'early_stop': True,\n",
    "    'min_delta': 1e-5, \n",
    "    'patience': 5,\n",
    "\n",
    "    'checkpoint': False,\n",
    "    'model_seed': 1337, # affects pytorch random generator\n",
    "    'random_seed': 0, # affects neg rxn sampling since it is random\n",
    "    \n",
    "    'rctfp_size': 16384,\n",
    "    'prodfp_size': 16384,\n",
    "    'fp_radius': 3,\n",
    "    'fp_type': 'sep',\n",
    "    \n",
    "    'num_neg': 9, # to be tuned, 9 seems to be superior to 5 (overfitting occured quickly)\n",
    "    \n",
    "    'path_to_pickle': os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle', \n",
    "    'checkpoint_path': os.getcwd()+'/checkpoints/',\n",
    "    'expt_name': '1layer_rad3_ELU'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "9mlGGCOZBEz4",
    "outputId": "03a6cbce-9c95-4556-da3d-8e99978b22b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FF_ebm(\n",
       "  (ffn): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=32768, out_features=512, bias=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init fingerprint-based feedforward EBM model \n",
    "model = FF_ebm(trainargs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K1cKDQ_9BOPd",
    "outputId": "604e4061-3050-4ccb-9627-7a03d16d7b16"
   },
   "outputs": [],
   "source": [
    "stats = train(model, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRSy2d3-edcr"
   },
   "outputs": [],
   "source": [
    "stats = test(model, stats, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvDHRmfi3ZaF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "twEVWkj63ZZ5"
   ],
   "name": "Feedforward_+_sepFP_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
