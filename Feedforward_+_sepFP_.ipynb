{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMGN51DE3ZZg"
   },
   "source": [
    "# To do: \n",
    "- build Ball Tree for cosine similarity\n",
    "- implement Bayesian optimisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c1pxoCjT4CbP",
    "outputId": "64daf71e-046a-485a-9cc9-8e781543e577"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLAB: Install RDKit. Takes 2-3 minutes \n",
    "# !wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# !chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "# !time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# !time conda install -q -y -c conda-forge python=3.7\n",
    "# !time conda install -q -y -c conda-forge rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "87OYfp5T4QDS",
    "outputId": "75529064-96b2-4865-c0d9-67487da207ee"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLAB\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8Q1rtww36JU"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLAB\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_nomap_noreagent.pickle' '/content/'\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/usr/local/lib/python3.7/site-packages/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSKTT4aD3ZZh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import rdqueries # faster than iterating atoms https://sourceforge.net/p/rdkit/mailman/message/34538007/ \n",
    "from rdkit.Chem.rdchem import Atom\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re \n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MINCF8E3ZZk"
   },
   "source": [
    "### References for papers using fingerprints as inputs\n",
    "https://pubs.acs.org/doi/pdf/10.1021/acscentsci.6b00219 and https://github.com/jnwei/neural_reaction_fingerprint\n",
    "http://pubs.acs.org.remotexs.ntu.edu.sg/doi/pdf/10.1021/ci5006614 (IPython notebooks in Supplementary Info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFZp1L1r3ZZl"
   },
   "source": [
    "### MorganFP not fixed values? why results not static? magnitude can be big, even w/ int8. do we need some form of scaling?? need to look into dtype also.  \n",
    "- int gives scarily big numbers\n",
    "- need to use int8 with large enough fp_size (e.g. 16384, which was used by <u>Reaction Condition Recommender ACS Cent. Sci. 2018, 4, 1465−1476</u>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU0QoD8e3ZZm",
    "outputId": "0ae96e8d-8718-4a8d-ea09-078b9339745e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print(create_rxn_MorganFP(sample_rxns[0], fp_size=16384)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfF81_7d3ZZp",
    "outputId": "bdd4c5da-91d7-4275-c180-bb6a2aa65576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196411728       370 325594256       370         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0         0         0         0         0         0\n",
      "         0         0]\n"
     ]
    }
   ],
   "source": [
    "# print(create_rxn_MorganFP(sample_rxns[0], fp_size=16384, dtype='int')[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMIpqIVk3ZZs"
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfFuy7g03ZZs"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_activation_function(activation: str) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Gets an activation function module given the name of the activation.\n",
    "    Supports:\n",
    "    * :code:`ReLU`\n",
    "    * :code:`LeakyReLU`\n",
    "    * :code:`PReLU`\n",
    "    * :code:`tanh`\n",
    "    * :code:`SELU`\n",
    "    * :code:`ELU`\n",
    "    :param activation: The name of the activation function.\n",
    "    :return: The activation function module.\n",
    "    \"\"\"\n",
    "    if activation == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'LeakyReLU':\n",
    "        return nn.LeakyReLU(0.1)\n",
    "    elif activation == 'PReLU':\n",
    "        return nn.PReLU()\n",
    "    elif activation == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif activation == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif activation == 'ELU':\n",
    "        return nn.ELU()\n",
    "    else:\n",
    "        raise ValueError(f'Activation \"{activation}\" not supported.')\n",
    "    \n",
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Initializes the weights of a model in place.\n",
    "    :param model: An PyTorch model.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant_(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1Cfy0AF3ZZv"
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxvJUWjr3ZZw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FF_ebm(nn.Module):\n",
    "    '''\n",
    "    trainargs: dictionary containing hyperparameters to be optimised, \n",
    "    hidden_sizes must be a list e.g. [1024, 512, 256]\n",
    "    \n",
    "    To do: bayesian optimisation\n",
    "    '''\n",
    "    def __init__(self, trainargs):\n",
    "        super(FF_ebm, self).__init__()\n",
    "        self.output_size = trainargs['output_size']\n",
    "        self.num_layers = len(trainargs['hidden_sizes']) + 1\n",
    "\n",
    "        if trainargs['model'] == 'FF_sep':\n",
    "          self.input_dim = trainargs['rctfp_size'] + trainargs['prodfp_size']\n",
    "        elif trainargs['model'] == 'FF_diff':\n",
    "          self.input_dim = trainargs['fp_size']\n",
    "\n",
    "        self.create_ffn(trainargs)\n",
    "        initialize_weights(self)\n",
    "    \n",
    "    def create_ffn(self, trainargs):\n",
    "        '''\n",
    "        Creates feed-forward network using trainargs dict\n",
    "        '''\n",
    "        dropout = nn.Dropout(trainargs['dropout'])\n",
    "        activation = get_activation_function(trainargs['activation'])\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, self.output_size)\n",
    "            ]\n",
    "        else:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, trainargs['hidden_sizes'][0])\n",
    "            ]\n",
    "            \n",
    "            # intermediate hidden layers \n",
    "            for i, layer in enumerate(range(self.num_layers - 2)):\n",
    "                ffn.extend([\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    nn.Linear(trainargs['hidden_sizes'][i], trainargs['hidden_sizes'][i+1]),\n",
    "                ])\n",
    "                \n",
    "            # last hidden layer\n",
    "            ffn.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(trainargs['hidden_sizes'][-1], self.output_size),\n",
    "            ])\n",
    "\n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        '''\n",
    "        Runs FF_ebm on input\n",
    "        \n",
    "        batch: a N x K x 1 tensor of N training samples, where each sample contains \n",
    "        a positive rxn on the first column, and K-1 negative rxn on subsequent columns \n",
    "        supplied by DataLoader on custom ReactionDataset \n",
    "        '''\n",
    "        energy_scores = self.ffn(batch) # tensor of size N x K x 1\n",
    "        return energy_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7EzzESW3ZZz"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeAWhxLw3ZZz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "def train_one(model, batch, optimizer, val=False):\n",
    "    '''\n",
    "    Trains model for 1 epoch \n",
    "    \n",
    "    TO DO: learning rate scheduler + logger \n",
    "    '''\n",
    "    model.zero_grad()\n",
    "    scores = model.forward(batch).squeeze(dim=-1) # scores: size N x K x 1 --> N x K after squeezing\n",
    "    \n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    probs = softmax(scores) # size N x K\n",
    "    \n",
    "    # positives are the 0-th index of each sample, add a small epsilon 1e-9 to stabilise log \n",
    "    loss = -torch.log(probs[:, 0]+1e-9).mean() # probs[:, 0] is size N x 1 --> sum/mean to 1 value\n",
    "    \n",
    "    if not val:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    #     if args.grad_clip: # gradient clipping if needed \n",
    "    #         nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.data.cpu()\n",
    "    \n",
    "def train(model, trainargs):\n",
    "    '''\n",
    "    Trains model for num_epochs provided in trainargs\n",
    "    Currently supports feed-forward networks: \n",
    "        FF_diff: takes as input a difference FP of fp_size & fp_radius\n",
    "        FF_sep: takes as input a concatenation of [reactants FP, product FP] \n",
    "    \n",
    "    trainargs: dict of params \n",
    "    '''\n",
    "    start = time.time()\n",
    "    stats = {'trainargs': trainargs} # to store training statistics \n",
    "    torch.manual_seed(trainargs['model_seed'])\n",
    "    random.seed(trainargs['random_seed'])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    optimizer = trainargs['optimizer'](model.parameters(), lr=trainargs['learning_rate'])\n",
    "    \n",
    "    train_dataset = ReactionDataset(trainargs['path_to_pickle'], 'train', trainargs)\n",
    "    train_loader = DataLoader(train_dataset, trainargs['batch_size'], shuffle=True)\n",
    "    mean_train_loss = []\n",
    "    \n",
    "    val_dataset = ReactionDataset(trainargs['path_to_pickle'], 'valid', trainargs)\n",
    "    val_loader = DataLoader(val_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "    min_val_loss = 1e9\n",
    "    mean_val_loss = []\n",
    "    \n",
    "    for epoch in np.arange(trainargs['epochs']):\n",
    "        model.train() # set model to training mode\n",
    "        train_loss = []\n",
    "        for batch in tqdm(train_loader): \n",
    "            batch = batch.to(device)\n",
    "            train_loss.append(train_one(model, batch, optimizer, val=False))\n",
    "            mean_train_loss.append(np.mean(train_loss)) \n",
    "            # print('train_loss: {}'.format(train_loss))\n",
    "        \n",
    "        model.eval() # validation mode\n",
    "        val_loss = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                batch = batch.to(device)\n",
    "                val_loss.append(train_one(model, batch, optimizer, val=True))\n",
    "        \n",
    "            if trainargs['early_stop'] and min_val_loss - np.mean(val_loss) < trainargs['min_delta']:\n",
    "                if trainargs['patience'] <= wait:\n",
    "                    print('Early stopped at the end of epoch: ', epoch)\n",
    "                    stats['early_stop_epoch'] = epoch \n",
    "                    break \n",
    "                else:\n",
    "                    wait += 1\n",
    "                    print('Decrease in val loss < min_delta, patience count: ', wait)\n",
    "            else:\n",
    "                wait = 0\n",
    "                min_val_loss = min(min_val_loss, np.mean(val_loss))\n",
    "            mean_val_loss.append(np.mean(val_loss))\n",
    "        \n",
    "        if trainargs['checkpoint']: # adapted from moco: main_moco.py\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model': trainargs['model'],\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                    'stats' : stats,\n",
    "                }, is_best=False, filename=trainargs['checkpoint_path']+'{}_{}_checkpoint_{:04d}.pth.tar'.format(trainargs['model'], trainargs['expt_name'], epoch))\n",
    "        \n",
    "        print('Epoch: {}, train_loss: {}, val_loss: {}'.format(epoch, \n",
    "                                         np.around(np.mean(train_loss), decimals=4), \n",
    "                                         np.around(np.mean(val_loss), decimals=4)))\n",
    "      \n",
    "    stats['mean_train_loss'] = mean_train_loss\n",
    "    stats['mean_val_loss'] = mean_val_loss\n",
    "    stats['min_val_loss'] = min_val_loss\n",
    "    stats['train_time'] = time.time() - start \n",
    "    # save training stats\n",
    "    torch.save(stats, trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(trainargs['model'], trainargs['expt_name']))\n",
    "    return stats \n",
    "              \n",
    "def test(model, stats, trainargs):\n",
    "    '''\n",
    "    Evaluates the model on the test set \n",
    "    '''\n",
    "    test_dataset = ReactionDataset(trainargs['path_to_pickle'], 'test', trainargs)\n",
    "    test_loader = DataLoader(test_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            test_loss.append(train_one(model, batch, optimizer, val=True))\n",
    "              \n",
    "    stats['test_loss'] = test_loss \n",
    "    stats['mean_test_loss'] = np.mean(test_loss)\n",
    "    print('train_time: {}'.format(stats['train_time']))\n",
    "    print('test_loss: {:.4f}'.format(stats['test_loss']))\n",
    "    # overrides training stats w/ training + test stats\n",
    "    torch.save(stats, trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(trainargs['model'], trainargs['expt_name'])) \n",
    "    return stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o12DGGe3ZZ2"
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYdV62U63ZZ3"
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/tutorials/blob/master/beginner_source/data_loading_tutorial.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def create_rxn_MorganFP(rxn_smi, fp_type='diff', radius=2, rctfp_size=16384, prodfp_size=16384, useChirality=True, dtype='int8'):\n",
    "    '''\n",
    "    fp_type: 'diff' or 'sep', \n",
    "    'diff' (difference):\n",
    "    Creates reaction MorganFP following Schneider et al in J. Chem. Inf. Model. 2015, 55, 1, 39–53\n",
    "    reactionFP = productFP - sum(reactantFPs)\n",
    "    \n",
    "    'sep' (separate):\n",
    "    Creates separate reactantsFP and productFP following Gao et al in ACS Cent. Sci. 2018, 4, 11, 1465–1476\n",
    "    '''\n",
    "    # initialise empty fp numpy arrays\n",
    "    if fp_type == 'diff':\n",
    "        diff_fp = np.empty(fp_size, dtype = dtype)\n",
    "    elif fp_type == 'sep':\n",
    "        rcts_fp = np.empty(rctfp_size, dtype = dtype)\n",
    "        prod_fp = np.empty(prodfp_size, dtype = dtype)\n",
    "    else:\n",
    "        print('ERROR: fp_type not recognised!')\n",
    "        return\n",
    "    \n",
    "    # create product FP\n",
    "    prod_mol = Chem.MolFromSmiles(rxn_smi.split('>')[-1])\n",
    "    try:\n",
    "        prod_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                        mol=prod_mol, radius=radius, nBits=prodfp_size, useChirality=useChirality)\n",
    "\n",
    "        fp = np.empty(prodfp_size, dtype = dtype)   # temporarily store numpy array as fp \n",
    "        DataStructs.ConvertToNumpyArray(prod_fp_bit, fp)\n",
    "        if fp_type == 'diff':\n",
    "            diff_fp += fp\n",
    "        elif fp_type == 'sep':\n",
    "            prod_fp = fp\n",
    "    except Exception as e:\n",
    "        print(\"Cannot build product fp due to {}\".format(e))\n",
    "        return\n",
    "                                  \n",
    "    # create reactant FPs, subtracting each from product FP\n",
    "    rcts_smi = rxn_smi.split('>')[0].split('.')\n",
    "    for rct_smi in rcts_smi:\n",
    "        rct_mol = Chem.MolFromSmiles(rct_smi)\n",
    "        try:\n",
    "            rct_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                            mol=rct_mol, radius=radius, nBits=rctfp_size, useChirality=useChirality)\n",
    "            fp = np.empty(rctfp_size, dtype = dtype)\n",
    "            DataStructs.ConvertToNumpyArray(rct_fp_bit, fp)\n",
    "            if fp_type == 'diff':\n",
    "                diff_fp -= fp\n",
    "            elif fp_type == 'sep':\n",
    "                rcts_fp += fp\n",
    "        except Exception as e:\n",
    "            print(\"Cannot build reactant fp due to {}\".format(e))\n",
    "            return\n",
    "    \n",
    "    if fp_type == 'diff':\n",
    "        return diff_fp\n",
    "    elif fp_type == 'sep':\n",
    "        return np.concatenate([rcts_fp, prod_fp])\n",
    "\n",
    "    \n",
    "class ReactionDataset(Dataset):\n",
    "    '''\n",
    "    The Dataset class ReactionDataset prepares training samples of length K: \n",
    "    [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1], ... where K-1 = num_neg \n",
    "\n",
    "    TO DO: can this be further optimised? Augmentation is the clear bottleneck during training\n",
    "    '''\n",
    "    def __init__(self, path_to_pickle, key, trainargs):\n",
    "        '''\n",
    "        pickle is dict w/ keys 'train', 'valid', 'test' each storing a list of rxn_smiles (str)\n",
    "        IMPORTANT: molAtomMapNumbers have been cleared during data pre-processing \n",
    "        ''' \n",
    "        # feels like loading the entire pickle is not feasible when the dataset gets larger \n",
    "        # is there a more memory-efficient way to do this? \n",
    "        with open(path_to_pickle, 'rb') as handle: \n",
    "            self.rxn_smiles = pickle.load(handle)[key] \n",
    "        self.fp_radius = trainargs['fp_radius']\n",
    "        self.rctfp_size = trainargs['rctfp_size']\n",
    "        self.prodfp_size = trainargs['prodfp_size']\n",
    "        self.fp_type = trainargs['fp_type']\n",
    "        self.num_neg = trainargs['num_neg']\n",
    "    \n",
    "    def random_sample_negative(self, pos_rxn_smi, pos_rxn_idx):\n",
    "        '''\n",
    "        Generates 1 negative reaction given a positive reaction SMILES\n",
    "        Returns neg_rxn_smi (str)\n",
    "        '''\n",
    "        rcts_smi = pos_rxn_smi.split('>')[0].split('.')\n",
    "        prod_smi = pos_rxn_smi.split('>')[-1]       \n",
    "            \n",
    "        rct_or_prod = random.choice([0, 1])\n",
    "        if rct_or_prod == 0: # randomly change one of the reactant(s)\n",
    "            orig_idx = random.choice(np.arange(len(rcts_smi))) # randomly choose 1 reactant to be replaced\n",
    "            \n",
    "            found = False\n",
    "            while not found: # searches randomly to find a different rct molecule to swap with \n",
    "                rdm_rxn_idx = random.choice(np.arange(len(self.rxn_smiles))) # randomly choose 1 rxn\n",
    "                if rdm_rxn_idx == pos_rxn_idx: continue # don't choose the original rxn\n",
    "                        \n",
    "                new_rxn_smi = self.rxn_smiles[rdm_rxn_idx]\n",
    "                new_rcts_smi = new_rxn_smi.split('>')[0].split('.')\n",
    "\n",
    "                rdm_rcts_idx = random.choice(np.arange(len(new_rcts_smi)))\n",
    "                if new_rcts_smi[rdm_rcts_idx] != rcts_smi[orig_idx]:\n",
    "                    found = True\n",
    "                    rcts_smi[orig_idx] = new_rcts_smi[rdm_rcts_idx]\n",
    "            \n",
    "        else: # randomly change the product            \n",
    "            found = False\n",
    "            while not found:  # searches randomly to find a different prod molecule to swap with \n",
    "                rdm_rxn_idx = random.choice(np.arange(len(self.rxn_smiles)))\n",
    "                if rdm_rxn_idx == pos_rxn_idx: continue # don't choose the original rxn\n",
    "                        \n",
    "                new_rxn_smi = self.rxn_smiles[rdm_rxn_idx]      \n",
    "                new_prod_smi = new_rxn_smi.split('>')[-1]\n",
    "                if new_prod_smi != prod_smi:\n",
    "                    found = True\n",
    "                    prod_smi = new_prod_smi\n",
    "        \n",
    "        return '{}>>{}'.format('.'.join(rcts_smi), prod_smi)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ''' \n",
    "        Returns 1 training sample in the form [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1]\n",
    "        num_neg: a hyperparameter to be tuned\n",
    "        \n",
    "        MAY DO: use while loops to retrieve MorganFP in case some of them fail (but this dataset is cleaned already)\n",
    "        '''\n",
    "        if torch.is_tensor(idx): # may not be needed, taken from data loading tutorial\n",
    "            idx = idx.tolist() \n",
    "        \n",
    "        pos_rxn_smi = self.rxn_smiles[idx]\n",
    "        pos_rxn_fp = create_rxn_MorganFP(pos_rxn_smi, radius=self.fp_radius, \n",
    "                                         rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n",
    "        \n",
    "        assert self.num_neg > 0, 'num_neg cannot be negative!'\n",
    "        neg_rxn_smis = [self.random_sample_negative(pos_rxn_smi, idx) for i in range(self.num_neg)]\n",
    "        neg_rxn_fps = [create_rxn_MorganFP(neg_rxn_smi, radius=self.fp_radius,  \n",
    "                                           rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n",
    "                      for neg_rxn_smi in neg_rxn_smis]\n",
    "        \n",
    "        return torch.Tensor([pos_rxn_fp, *neg_rxn_fps])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rxn_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twEVWkj63ZZ5"
   },
   "source": [
    "### Preliminary checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjffU9Uk3ZZ5"
   },
   "outputs": [],
   "source": [
    "trainargs = {\n",
    "    'model': 'FF_sep',\n",
    "    'hidden_sizes': [512],  \n",
    "    'output_size': 1,\n",
    "    'dropout': 0.5, # adapted from Reaction Condition Recommender   \n",
    "    \n",
    "    'batch_size': 256,\n",
    "    'activation': 'ELU', # trying ELU for its differentiability everywhere (vs ReLU which is not differentiable at x=0)\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 1e-6, # to try: integrate w/ fast.ai lr_finder & lr_schedulers \n",
    "    'epochs': 50,\n",
    "    'early_stop': True,\n",
    "    'min_delta': 1e-5, \n",
    "    'patience': 5,\n",
    "\n",
    "    'checkpoint': True,\n",
    "    'model_seed': 1337,\n",
    "    'random_seed': 0, # affects neg rxn sampling since it is random\n",
    "    \n",
    "    'rctfp_size': 16384,\n",
    "    'prodfp_size': 16384,\n",
    "    'fp_radius': 3,\n",
    "    'fp_type': 'sep',\n",
    "    \n",
    "    'num_neg': 9, # to be tuned, 9 seems to be superior to 5 (overfitting occured quickly)\n",
    "    \n",
    "    'path_to_pickle': os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle', \n",
    "    'checkpoint_path': os.getcwd()+'/checkpoints/',\n",
    "    'expt_name': '1layer_rad3_ELU'\n",
    "}\n",
    "\n",
    "train_dataset = ReactionDataset(os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle',\n",
    "                               'train',\n",
    "                               trainargs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FF_ebm(trainargs)\n",
    "model.to(device)\n",
    "train_loader = DataLoader(train_dataset, trainargs['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "-Q2oD8zk3ZZ8",
    "outputId": "886362d3-f8f0-49ef-bbb6-d70355ea5c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 6, 32768]) torch.Size([256, 6, 1])\n",
      "1 torch.Size([256, 6, 32768]) torch.Size([256, 6, 1])\n",
      "2 torch.Size([256, 6, 32768]) torch.Size([256, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched = sample_batched.to(device)\n",
    "    i_scores = model.forward(sample_batched)\n",
    "    print(i_batch, sample_batched.shape, i_scores.shape)\n",
    "\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "l861SYYo3ZZ-",
    "outputId": "c2e69f32-45ec-478f-b8f8-f8789edf1436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.3954, device='cuda:0', grad_fn=<NegBackward>), torch.Size([256]))"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = i_scores.squeeze(dim=-1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "probs = softmax(scores) # size N x K\n",
    "\n",
    "# positives are the 0-th index of each sample \n",
    "loss = -torch.log(probs[:, 0]).mean() # probs[:, 0] is size N x 1 --> sum to 1 value\n",
    "loss, probs[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "evHcirGbGZUL",
    "outputId": "ad0d59da-4298-465a-c168-6f425460239f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3954)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ti5ndWB3ZaA"
   },
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "890bgQ783ZaB"
   },
   "outputs": [],
   "source": [
    "trainargs = {\n",
    "    'model': 'FF_sep',\n",
    "    'hidden_sizes': [512],  \n",
    "    'output_size': 1,\n",
    "    'dropout': 0.5, # adapted from Reaction Condition Recommender   \n",
    "    \n",
    "    'batch_size': 256,\n",
    "    'activation': 'ELU', # trying ELU for its differentiability everywhere (vs ReLU which is not differentiable at x=0)\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 1e-6, # to try: integrate w/ fast.ai lr_finder & lr_schedulers \n",
    "    'epochs': 50,\n",
    "    'early_stop': True,\n",
    "    'min_delta': 1e-5, \n",
    "    'patience': 5,\n",
    "\n",
    "    'checkpoint': False,\n",
    "    'model_seed': 1337, # affects pytorch random generator\n",
    "    'random_seed': 0, # affects neg rxn sampling since it is random\n",
    "    \n",
    "    'rctfp_size': 16384,\n",
    "    'prodfp_size': 16384,\n",
    "    'fp_radius': 3,\n",
    "    'fp_type': 'sep',\n",
    "    \n",
    "    'num_neg': 9, # to be tuned, 9 seems to be superior to 5 (overfitting occured quickly)\n",
    "    \n",
    "    'path_to_pickle': os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle', \n",
    "    'checkpoint_path': os.getcwd()+'/checkpoints/',\n",
    "    'expt_name': '1layer_rad3_ELU'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "9mlGGCOZBEz4",
    "outputId": "03a6cbce-9c95-4556-da3d-8e99978b22b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FF_ebm(\n",
       "  (ffn): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=32768, out_features=512, bias=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init fingerprint-based feedforward EBM model \n",
    "model = FF_ebm(trainargs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K1cKDQ_9BOPd",
    "outputId": "604e4061-3050-4ccb-9627-7a03d16d7b16"
   },
   "outputs": [],
   "source": [
    "stats = train(model, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRSy2d3-edcr"
   },
   "outputs": [],
   "source": [
    "stats = test(model, stats, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvDHRmfi3ZaF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "twEVWkj63ZZ5"
   ],
   "name": "Feedforward_+_sepFP_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
