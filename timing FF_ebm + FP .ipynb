{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMGN51DE3ZZg"
   },
   "source": [
    "### To do: \n",
    "- build Ball Tree for cosine similarity\n",
    "- implement Bayesian optimisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c1pxoCjT4CbP",
    "outputId": "4f7e429c-1150-4f7f-8d34-da78a60281ff"
   },
   "outputs": [],
   "source": [
    "# Install RDKit. Takes 2-3 minutes\n",
    "# !wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# !chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "# !time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# !time conda install -q -y -c conda-forge python=3.7\n",
    "# !time conda install -q -y -c conda-forge rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "87OYfp5T4QDS",
    "outputId": "7297a371-2c64-4395-de18-8f8b821bd88e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8Q1rtww36JU"
   },
   "outputs": [],
   "source": [
    "# DRIVE_PATH_TO_PICKLE = '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_nomap_noreagent.pickle'\n",
    "# VM_PATH_TO_PICKLE = '/content/'\n",
    "\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_nomap_noreagent.pickle' '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSKTT4aD3ZZh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/usr/local/lib/python3.7/site-packages/') \n",
    "# for Colab \n",
    "import os\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import rdqueries # faster than iterating atoms https://sourceforge.net/p/rdkit/mailman/message/34538007/ \n",
    "from rdkit.Chem.rdchem import Atom\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re \n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMIpqIVk3ZZs"
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfFuy7g03ZZs"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_activation_function(activation: str) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Gets an activation function module given the name of the activation.\n",
    "    Supports:\n",
    "    * :code:`ReLU`\n",
    "    * :code:`LeakyReLU`\n",
    "    * :code:`PReLU`\n",
    "    * :code:`tanh`\n",
    "    * :code:`SELU`\n",
    "    * :code:`ELU`\n",
    "    :param activation: The name of the activation function.\n",
    "    :return: The activation function module.\n",
    "    \"\"\"\n",
    "    if activation == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'LeakyReLU':\n",
    "        return nn.LeakyReLU(0.1)\n",
    "    elif activation == 'PReLU':\n",
    "        return nn.PReLU()\n",
    "    elif activation == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif activation == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif activation == 'ELU':\n",
    "        return nn.ELU()\n",
    "    else:\n",
    "        raise ValueError(f'Activation \"{activation}\" not supported.')\n",
    "    \n",
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Initializes the weights of a model in place.\n",
    "    :param model: An PyTorch model.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant_(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1Cfy0AF3ZZv"
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxvJUWjr3ZZw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FF_ebm(nn.Module):\n",
    "    '''\n",
    "    trainargs: dictionary containing hyperparameters to be optimised, \n",
    "    hidden_sizes must be a list e.g. [1024, 512, 256]\n",
    "    \n",
    "    To do: bayesian optimisation\n",
    "    '''\n",
    "    def __init__(self, trainargs):\n",
    "        super(FF_ebm, self).__init__()\n",
    "        self.output_size = trainargs['output_size']\n",
    "        self.num_layers = len(trainargs['hidden_sizes']) + 1\n",
    "\n",
    "        if trainargs['model'] == 'FF_sep':\n",
    "          self.input_dim = trainargs['rctfp_size'] + trainargs['prodfp_size'] # will be rctfp_size + prodfp_size for FF_sep\n",
    "        elif trainargs['model'] == 'FF_diff':\n",
    "          self.input_dim = trainargs['rctfp_size']\n",
    "          assert trainargs['rctfp_size'] == trainargs['prodfp_size'], 'rctfp_size != prodfp_size, unable to make difference FPs!!!'\n",
    "\n",
    "        self.create_ffn(trainargs)\n",
    "        initialize_weights(self)  # is it necessary to initialize weights?? \n",
    "    \n",
    "    def create_ffn(self, trainargs):\n",
    "        '''\n",
    "        Creates feed-forward network using trainargs dict\n",
    "        '''\n",
    "        dropout = nn.Dropout(trainargs['dropout'])\n",
    "        activation = get_activation_function(trainargs['activation'])\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, self.output_size)\n",
    "            ]\n",
    "        else:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, trainargs['hidden_sizes'][0])\n",
    "            ]\n",
    "            \n",
    "            # intermediate hidden layers \n",
    "            for i, layer in enumerate(range(self.num_layers - 2)):\n",
    "                ffn.extend([\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    nn.Linear(trainargs['hidden_sizes'][i], trainargs['hidden_sizes'][i+1]),\n",
    "                ])\n",
    "                \n",
    "            # last hidden layer\n",
    "            ffn.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(trainargs['hidden_sizes'][-1], self.output_size),\n",
    "            ])\n",
    "\n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        '''\n",
    "        Runs FF_ebm on input\n",
    "        \n",
    "        batch: a N x K x 1 tensor of N training samples, where each sample contains \n",
    "        a positive rxn on the first column, and K-1 negative rxn on subsequent columns \n",
    "        supplied by DataLoader on custom ReactionDataset \n",
    "        '''\n",
    "        energy_scores = self.ffn(batch) # tensor of size N x K x 1\n",
    "        return energy_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7EzzESW3ZZz"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeAWhxLw3ZZz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class Run():\n",
    "    def __init__(self, model, trainargs):\n",
    "        self.device = trainargs['device']\n",
    "        model = model.to(self.device)\n",
    "        self.model = model\n",
    "        self.optimizer = trainargs['optimizer'](model.parameters(), lr=trainargs['learning_rate'])\n",
    "        self.trainargs = trainargs \n",
    "\n",
    "        train_dataset = ReactionDataset(trainargs['path_to_pickle'], 'train', trainargs)\n",
    "        self.train_loader = DataLoader(train_dataset, trainargs['batch_size'], shuffle=True)\n",
    "        \n",
    "        val_dataset = ReactionDataset(trainargs['path_to_pickle'], 'valid', trainargs)\n",
    "        self.val_loader = DataLoader(val_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "        \n",
    "        test_dataset = ReactionDataset(self.trainargs['path_to_pickle'], 'test', self.trainargs)\n",
    "        self.test_loader = DataLoader(test_dataset, 2 * self.trainargs['batch_size'], shuffle=False)\n",
    "        del train_dataset, val_dataset, test_dataset\n",
    "\n",
    "        self.mean_train_loss = []\n",
    "        self.min_val_loss = 1e9\n",
    "        self.mean_val_loss = []\n",
    "        self.stats = {'trainargs': self.trainargs} # to store training statistics  \n",
    "\n",
    "        torch.manual_seed(trainargs['model_seed'])\n",
    "        random.seed(trainargs['random_seed'])\n",
    "    \n",
    "    def train_one(self, batch, val=False):\n",
    "        '''\n",
    "        Trains model for 1 epoch \n",
    "\n",
    "        TO DO: learning rate scheduler + logger \n",
    "        '''\n",
    "        self.model.zero_grad()\n",
    "        scores = self.model.forward(batch).squeeze(dim=-1) # scores: size N x K x 1 --> N x K after squeezing\n",
    "\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        probs = softmax(scores) # size N x K\n",
    "\n",
    "        # positives are the 0-th index of each sample, add a small epsilon 1e-9 to stabilise log \n",
    "        loss = -torch.log(probs[:, 0]+1e-9).mean() # probs[:, 0] is size N x 1 --> sum/mean to 1 value\n",
    "\n",
    "        if not val:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        #     if args.grad_clip:\n",
    "        #         nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return loss.data.cpu()\n",
    "\n",
    "    def train(self):\n",
    "        '''\n",
    "        Trains model for num_epochs provided in trainargs\n",
    "        Currently supports feed-forward networks: \n",
    "            FF_diff: takes as input a difference FP of fp_size & fp_radius\n",
    "            FF_sep: takes as input a concatenation of [reactants FP, product FP] \n",
    "\n",
    "        trainargs: dict of params \n",
    "        '''\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in np.arange(self.trainargs['epochs']):\n",
    "            self.model.train() # set model to training mode\n",
    "            train_loss = []\n",
    "            for batch in tqdm(self.train_loader): \n",
    "                batch = batch.to(self.device)\n",
    "                train_loss.append(self.train_one(batch, val=False))\n",
    "                self.mean_train_loss.append(np.mean(train_loss)) \n",
    "                # print('train_loss: {}'.format(train_loss))\n",
    "\n",
    "            self.model.eval() # validation mode\n",
    "            val_loss = []\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(self.val_loader):\n",
    "                    batch = batch.to(self.device)\n",
    "                    val_loss.append(self.train_one(batch, val=True))\n",
    "\n",
    "                if self.trainargs['early_stop'] and self.min_val_loss - np.mean(val_loss) < self.trainargs['min_delta']:\n",
    "                    if self.trainargs['patience'] <= wait:\n",
    "                        print('Early stopped at the end of epoch: ', epoch)\n",
    "                        print('mean_val_loss: ', np.mean(val_loss))\n",
    "                        stats['early_stop_epoch'] = epoch \n",
    "                        break \n",
    "                    else:\n",
    "                        wait += 1\n",
    "                        print('Decrease in val loss < min_delta, patience count: ', wait)\n",
    "                else:\n",
    "                    wait = 0\n",
    "                    self.min_val_loss = min(self.min_val_loss, np.mean(val_loss))\n",
    "                self.mean_val_loss.append(np.mean(val_loss))\n",
    "\n",
    "            if self.trainargs['checkpoint']: # adapted from moco: main_moco.py\n",
    "                save_checkpoint({\n",
    "                        'epoch': epoch + 1,\n",
    "                        'model': self.trainargs['model'],\n",
    "                        'state_dict': self.model.state_dict(),\n",
    "                        'optimizer' : self.optimizer.state_dict(),\n",
    "                        'stats' : self.stats,\n",
    "                    }, is_best=False, \n",
    "                    filename=self.trainargs['checkpoint_path']+'{}_{}_checkpoint_{:04d}.pth.tar'.format(\n",
    "                        self.trainargs['model'], self.trainargs['expt_name'], epoch))\n",
    "\n",
    "            print('Epoch: {}, train_loss: {}, val_loss: {}'.format(epoch, \n",
    "                                             np.around(np.mean(train_loss), decimals=4), \n",
    "                                             np.around(np.mean(val_loss), decimals=4)))\n",
    "\n",
    "        self.stats['mean_train_loss'] = self.mean_train_loss\n",
    "        self.stats['mean_val_loss'] = self.mean_val_loss\n",
    "        self.stats['min_val_loss'] = self.min_val_loss\n",
    "        self.stats['train_time'] = time.time() - start \n",
    "        # save training stats\n",
    "        torch.save(self.stats, self.trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(\n",
    "            self.trainargs['model'], self.trainargs['expt_name']))\n",
    "\n",
    "    def test(self):\n",
    "        '''\n",
    "        Evaluates the model on the test set \n",
    "        '''\n",
    "        test_loss = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader):\n",
    "                batch = batch.to(self.device)\n",
    "                test_loss.append(self.train_one(batch, val=True))\n",
    "\n",
    "        self.stats['test_loss'] = test_loss \n",
    "        self.stats['mean_test_loss'] = np.mean(test_loss)\n",
    "        print('train_time: {}'.format(self.stats['train_time']))\n",
    "        print('test_loss: {}'.format(self.stats['test_loss']))\n",
    "        print('mean_test_loss: {}'.format(self.stats['mean_test_loss']))\n",
    "        # overrides training stats w/ training + test stats\n",
    "        torch.save(self.stats, self.trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(\n",
    "            self.trainargs['model'], self.trainargs['expt_name'])) \n",
    "\n",
    "    def get_scores(self, dataloader):\n",
    "        ''' \n",
    "        Gets raw energy values (scores) from a trained model on a given dataloader\n",
    "        '''\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "          for batch in tqdm(dataloader):\n",
    "              batch = batch.to(self.device)\n",
    "              self.model.zero_grad()\n",
    "              scores.append(self.model.forward(batch).squeeze(dim=-1)) \n",
    "            # scores: size N x K x 1 --> N x K after squeezing\n",
    "\n",
    "        return torch.cat(scores, dim=0)\n",
    "\n",
    "    def get_top1_acc(self, dataloader):\n",
    "        '''\n",
    "        Computes top-1 accuracy of trained model in classifying feasible vs infeasible chemical rxns\n",
    "        (i.e. maximum energy score assigned to label 0 of each training sample) \n",
    "        '''\n",
    "        scores = self.get_scores(dataloader)\n",
    "        predicted_labels = torch.argmax(scores, dim=1, keepdim=False)\n",
    "        \n",
    "        return torch.where(predicted_labels == 0)[0].shape[0]/predicted_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o12DGGe3ZZ2"
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYdV62U63ZZ3"
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/tutorials/blob/master/beginner_source/data_loading_tutorial.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def create_rxn_MorganFP(rxn_smi, fp_type='diff', radius=2, \n",
    "                        rctfp_size=16384, prodfp_size=16384, \n",
    "                        useChirality=True, dtype='int8'):\n",
    "    '''\n",
    "    fp_type: 'diff' or 'sep', \n",
    "    'diff' (difference):\n",
    "    Creates reaction MorganFP following Schneider et al in J. Chem. Inf. Model. 2015, 55, 1, 39–53\n",
    "    reactionFP = productFP - sum(reactantFPs)\n",
    "    \n",
    "    'sep' (separate):\n",
    "    Creates separate reactantsFP and productFP following Gao et al in ACS Cent. Sci. 2018, 4, 11, 1465–1476\n",
    "    '''\n",
    "    # initialise empty fp numpy arrays\n",
    "    if fp_type == 'diff':\n",
    "        diff_fp = np.empty(rctfp_size, dtype = dtype)\n",
    "    elif fp_type == 'sep':\n",
    "        rcts_fp = np.empty(rctfp_size, dtype = dtype)\n",
    "        prod_fp = np.empty(prodfp_size, dtype = dtype)\n",
    "    else:\n",
    "        print('ERROR: fp_type not recognised!')\n",
    "        return\n",
    "    \n",
    "    # create product FP\n",
    "    prod_mol = Chem.MolFromSmiles(rxn_smi.split('>')[-1])\n",
    "    try:\n",
    "        prod_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                        mol=prod_mol, radius=radius, nBits=prodfp_size, useChirality=useChirality)\n",
    "\n",
    "        fp = np.empty(prodfp_size, dtype = dtype)   # temporarily store numpy array as fp \n",
    "        DataStructs.ConvertToNumpyArray(prod_fp_bit, fp)\n",
    "        if fp_type == 'diff':\n",
    "            diff_fp += fp\n",
    "        elif fp_type == 'sep':\n",
    "            prod_fp = fp\n",
    "    except Exception as e:\n",
    "        print(\"Cannot build product fp due to {}\".format(e))\n",
    "        return\n",
    "                                  \n",
    "    # create reactant FPs, subtracting each from product FP\n",
    "    rcts_smi = rxn_smi.split('>')[0].split('.')\n",
    "    for rct_smi in rcts_smi:\n",
    "        rct_mol = Chem.MolFromSmiles(rct_smi)\n",
    "        try:\n",
    "            rct_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                            mol=rct_mol, radius=radius, nBits=rctfp_size, useChirality=useChirality)\n",
    "            fp = np.empty(rctfp_size, dtype = dtype)\n",
    "            DataStructs.ConvertToNumpyArray(rct_fp_bit, fp)\n",
    "            if fp_type == 'diff':\n",
    "                diff_fp -= fp\n",
    "            elif fp_type == 'sep':\n",
    "                rcts_fp += fp\n",
    "        except Exception as e:\n",
    "            print(\"Cannot build reactant fp due to {}\".format(e))\n",
    "            return\n",
    "    \n",
    "    if fp_type == 'diff':\n",
    "        return diff_fp\n",
    "    elif fp_type == 'sep':\n",
    "        return np.concatenate([rcts_fp, prod_fp])\n",
    "\n",
    "    \n",
    "class ReactionDataset(Dataset):\n",
    "    '''\n",
    "    The Dataset class ReactionDataset prepares training samples of length K: \n",
    "    [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1], ... where K-1 = num_neg \n",
    "\n",
    "    TO DO: can this be further optimised? Augmentation is the clear bottleneck during training\n",
    "    '''\n",
    "    def __init__(self, path_to_pickle, key, trainargs):\n",
    "        '''\n",
    "        pickle is dict w/ keys 'train', 'valid', 'test' each storing a list of rxn_smiles (str)\n",
    "        IMPORTANT: molAtomMapNumbers have been cleared during data pre-processing \n",
    "        ''' \n",
    "        # feels like loading the entire pickle is not feasible when the dataset gets larger \n",
    "        # is there a more memory-efficient way to do this? \n",
    "        with open(path_to_pickle, 'rb') as handle: \n",
    "            self.rxn_smiles = pickle.load(handle)[key] \n",
    "        self.fp_radius = trainargs['fp_radius']\n",
    "        self.fp_type = trainargs['fp_type']\n",
    "        self.rctfp_size = trainargs['rctfp_size']\n",
    "        self.prodfp_size = trainargs['prodfp_size']\n",
    "        self.num_neg = trainargs['num_neg']\n",
    "    \n",
    "    def random_sample_negative(self, pos_rxn_smi, pos_rxn_idx):\n",
    "        '''\n",
    "        Generates 1 negative reaction given a positive reaction SMILES\n",
    "        Returns neg_rxn_smi (str)\n",
    "        '''\n",
    "        rcts_smi = pos_rxn_smi.split('>')[0].split('.')\n",
    "        prod_smi = pos_rxn_smi.split('>')[-1]       \n",
    "            \n",
    "        rct_or_prod = random.choice([0, 1])\n",
    "        if rct_or_prod == 0: # randomly change one of the reactant(s)\n",
    "            orig_idx = random.choice(np.arange(len(rcts_smi))) # randomly choose 1 reactant to be replaced\n",
    "            \n",
    "            found = False\n",
    "            while not found: # searches randomly to find a different rct molecule to swap with \n",
    "                rdm_rxn_idx = random.choice(np.arange(len(self.rxn_smiles))) # randomly choose 1 rxn\n",
    "                if rdm_rxn_idx == pos_rxn_idx: continue # don't choose the original rxn\n",
    "                        \n",
    "                new_rxn_smi = self.rxn_smiles[rdm_rxn_idx]\n",
    "                new_rcts_smi = new_rxn_smi.split('>')[0].split('.')\n",
    "\n",
    "                rdm_rcts_idx = random.choice(np.arange(len(new_rcts_smi)))\n",
    "                if new_rcts_smi[rdm_rcts_idx] != rcts_smi[orig_idx]:\n",
    "                    found = True\n",
    "                    rcts_smi[orig_idx] = new_rcts_smi[rdm_rcts_idx]\n",
    "            \n",
    "        else: # randomly change the product            \n",
    "            found = False\n",
    "            while not found:  # searches randomly to find a different prod molecule to swap with \n",
    "                rdm_rxn_idx = random.choice(np.arange(len(self.rxn_smiles)))\n",
    "                if rdm_rxn_idx == pos_rxn_idx: continue # don't choose the original rxn\n",
    "                        \n",
    "                new_rxn_smi = self.rxn_smiles[rdm_rxn_idx]      \n",
    "                new_prod_smi = new_rxn_smi.split('>')[-1]\n",
    "                if new_prod_smi != prod_smi:\n",
    "                    found = True\n",
    "                    prod_smi = new_prod_smi\n",
    "        \n",
    "        return '{}>>{}'.format('.'.join(rcts_smi), prod_smi)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "      ''' \n",
    "      Returns 1 training sample in the form [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1]\n",
    "      num_neg: a hyperparameter to be tuned\n",
    "      '''\n",
    "      if torch.is_tensor(idx): # may not be needed, taken from data loading tutorial\n",
    "          idx = idx.tolist() \n",
    "\n",
    "      pos_rxn_smi = self.rxn_smiles[idx]\n",
    "      pos_rxn_fp = create_rxn_MorganFP(pos_rxn_smi, radius=self.fp_radius, \n",
    "                                      rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n",
    "      \n",
    "      assert self.num_neg > 0, 'num_neg cannot be negative!'\n",
    "      neg_rxn_smis = [self.random_sample_negative(pos_rxn_smi, idx) for i in range(self.num_neg)]\n",
    "      neg_rxn_fps = [create_rxn_MorganFP(neg_rxn_smi, radius=self.fp_radius,  \n",
    "                                        rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n",
    "                    for neg_rxn_smi in neg_rxn_smis]\n",
    "\n",
    "      return torch.Tensor([pos_rxn_fp, *neg_rxn_fps])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rxn_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ti5ndWB3ZaA"
   },
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "890bgQ783ZaB"
   },
   "outputs": [],
   "source": [
    "trainargs = {\n",
    "    'model': 'FF_diff', # must change both model & fp_type \n",
    "    'hidden_sizes': [256],  \n",
    "    'output_size': 1,\n",
    "    'dropout': 0.3, # adapted from Reaction Condition Recommender   \n",
    "    \n",
    "    'batch_size': 512,\n",
    "    'activation': 'ReLU', # trying ELU for its differentiability everywhere (vs ReLU which is not differentiable at x=0)\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 5e-5, # to try: integrate w/ fast.ai lr_finder & lr_schedulers \n",
    "    'epochs': 50,\n",
    "    'early_stop': True,\n",
    "    'min_delta': 1e-5, \n",
    "    'patience': 3,\n",
    "\n",
    "    'checkpoint': True,\n",
    "    'model_seed': 1337,\n",
    "    'random_seed': 0, # affects neg rxn sampling since it is random\n",
    "    \n",
    "    'rctfp_size': 1024, # if fp_type == 'diff', ensure that both rctfp_size & prodfp_size are identical!\n",
    "    'prodfp_size': 1024,\n",
    "    'fp_radius': 2,\n",
    "    'fp_type': 'diff',\n",
    "    \n",
    "    'num_neg': 5, \n",
    "    \n",
    "    'path_to_pickle': os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle', \n",
    "    'checkpoint_path': os.getcwd()+'/checkpoints/',\n",
    "    'expt_name': 'timing',\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:29<00:00,  3.41s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:34<00:00,  3.48s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:46<00:00,  3.62s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:27<00:00,  3.39s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:07<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_dataset = ReactionDataset(trainargs['path_to_pickle'], 'train', trainargs)\n",
    "train_loader = DataLoader(train_dataset, trainargs['batch_size'], shuffle=True)\n",
    "\n",
    "for i in range(5): # repeat train_loader 5 times\n",
    "    for batch in tqdm(train_loader): \n",
    "        batch = batch.to(trainargs['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "9mlGGCOZBEz4",
    "outputId": "93c963dd-f709-4f35-991a-880268233e72"
   },
   "outputs": [],
   "source": [
    "# initialises fingerprint-based feedforward EBM model \n",
    "model = FF_ebm(trainargs)\n",
    "run = Run(model, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oAQVPmtNBAuo",
    "outputId": "d4d3cb35-84d5-4104-ce9b-b67a88db7d06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:49<00:00,  3.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.26s/it]\n",
      "  0%|                                                                                           | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 2.082200050354004, val_loss: 1.8336999416351318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:39<00:00,  3.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.35s/it]\n",
      "  0%|                                                                                           | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss: 1.951200008392334, val_loss: 1.71589994430542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:33<00:00,  3.46s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:32<00:00,  6.51s/it]\n",
      "  0%|                                                                                           | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train_loss: 1.8630000352859497, val_loss: 1.6748000383377075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [05:06<00:00,  3.88s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:34<00:00,  6.96s/it]\n",
      "  0%|                                                                                           | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, train_loss: 1.8260999917984009, val_loss: 1.6518000364303589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:56<00:00,  3.75s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:35<00:00,  7.12s/it]\n",
      "  0%|                                                                                           | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train_loss: 1.7863999605178833, val_loss: 1.604200005531311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [05:14<00:00,  3.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:34<00:00,  6.93s/it]\n",
      "  0%|                                                                                           | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrease in val loss < min_delta, patience count:  1\n",
      "Epoch: 5, train_loss: 1.743899941444397, val_loss: 1.6088999509811401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████                                                      | 27/79 [01:47<04:01,  4.65s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a9cf1f8d39fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-ce1092168081>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set model to training mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-360e16ada050>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    150\u001b[0m       neg_rxn_fps = [create_rxn_MorganFP(neg_rxn_smi, radius=self.fp_radius,  \n\u001b[0;32m    151\u001b[0m                                         rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n\u001b[1;32m--> 152\u001b[1;33m                     for neg_rxn_smi in neg_rxn_smis]\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos_rxn_fp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mneg_rxn_fps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-360e16ada050>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    150\u001b[0m       neg_rxn_fps = [create_rxn_MorganFP(neg_rxn_smi, radius=self.fp_radius,  \n\u001b[0;32m    151\u001b[0m                                         rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size, fp_type=self.fp_type)\n\u001b[1;32m--> 152\u001b[1;33m                     for neg_rxn_smi in neg_rxn_smis]\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos_rxn_fp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mneg_rxn_fps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-360e16ada050>\u001b[0m in \u001b[0;36mcreate_rxn_MorganFP\u001b[1;34m(rxn_smi, fp_type, radius, rctfp_size, prodfp_size, useChirality, dtype)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mDataStructs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvertToNumpyArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrct_fp_bit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfp_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'diff'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mdiff_fp\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mfp_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sep'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mrcts_fp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfmFtR4qBjrf"
   },
   "outputs": [],
   "source": [
    "run.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_o3lhYIioRA"
   },
   "outputs": [],
   "source": [
    "run.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0R5fkcaEBkV5"
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "display.Audio(url=\"https://static.sfdict.com/audio/C07/C0702600.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NwqAIqlwBkci"
   },
   "source": [
    "### archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "WkC6sg1w4SiA",
    "outputId": "4b657609-3d97-4544-b7b0-d10a02ddb4e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_time: 593.6578595638275\n",
      "test_loss: [tensor(2.1238), tensor(1.8693), tensor(1.9509), tensor(1.8589), tensor(2.0245)]\n",
      "mean_test_loss: 1.9654802083969116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stats = test(model, stats, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j6F9aiIp6gCP",
    "outputId": "cea2c57d-0637-465d-e314-4b7052d0f7a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ReactionDataset(trainargs['path_to_pickle'], 'test', trainargs)\n",
    "test_loader = DataLoader(test_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "\n",
    "test_scores = get_scores(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "YcIv0BOU72G-",
    "outputId": "c381fdd8-3151-4c5d-f1f9-7dd57a766dad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 31.7568,   0.6232],\n",
       "        [  0.6059,   1.6602],\n",
       "        [  0.5389,   0.5825],\n",
       "        [  0.6551,   1.1973],\n",
       "        [  0.6551,   0.2540],\n",
       "        [  0.5131,   1.4135],\n",
       "        [  0.7937,   0.3980],\n",
       "        [  1.1794,   0.3391],\n",
       "        [  0.9399,   1.2554],\n",
       "        [  1.1911,   0.8047],\n",
       "        [  0.3444,   1.1524],\n",
       "        [  1.5007,   0.3585],\n",
       "        [  1.1836,   1.3253],\n",
       "        [  1.5233,   1.3346],\n",
       "        [-13.7237,   1.2437],\n",
       "        [  1.3159,   0.5960],\n",
       "        [  1.3634,   0.2379],\n",
       "        [  1.0724,   0.2915],\n",
       "        [  0.3685,   1.1581],\n",
       "        [  1.3275,   1.2685]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xn0K4LBo9BiK",
    "outputId": "55ea9c4f-f935-4305-b064-2d528cbfd263"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stop_epoch': 5,\n",
       " 'mean_test_loss': 1.9654802,\n",
       " 'mean_train_loss': [3.79339,\n",
       "  4.147327,\n",
       "  4.1827908,\n",
       "  4.0512996,\n",
       "  4.0508604,\n",
       "  4.0648336,\n",
       "  4.0370502,\n",
       "  4.0900755,\n",
       "  4.050375,\n",
       "  4.071214,\n",
       "  4.116623,\n",
       "  4.1053796,\n",
       "  4.14862,\n",
       "  4.1839542,\n",
       "  4.147746,\n",
       "  4.131441,\n",
       "  4.1477966,\n",
       "  4.174607,\n",
       "  4.1787944,\n",
       "  4.1921945,\n",
       "  4.1756163,\n",
       "  4.181274,\n",
       "  4.191578,\n",
       "  4.2076545,\n",
       "  4.203568,\n",
       "  4.2123814,\n",
       "  4.213587,\n",
       "  4.215596,\n",
       "  4.2241488,\n",
       "  4.2082777,\n",
       "  4.2193255,\n",
       "  4.2122393,\n",
       "  4.200224,\n",
       "  4.1940913,\n",
       "  4.19744,\n",
       "  4.1791553,\n",
       "  4.1880274,\n",
       "  4.198185,\n",
       "  4.2058096,\n",
       "  4.218196,\n",
       "  4.205752,\n",
       "  4.1958714,\n",
       "  4.180777,\n",
       "  4.176884,\n",
       "  4.179717,\n",
       "  4.1756716,\n",
       "  4.186036,\n",
       "  4.1780953,\n",
       "  4.180181,\n",
       "  4.1730504,\n",
       "  4.171473,\n",
       "  4.1738334,\n",
       "  4.1639833,\n",
       "  4.154662,\n",
       "  4.146443,\n",
       "  4.146165,\n",
       "  4.142267,\n",
       "  4.142902,\n",
       "  4.1295094,\n",
       "  4.1229115,\n",
       "  4.1232905,\n",
       "  4.1239963,\n",
       "  4.118799,\n",
       "  4.118685,\n",
       "  4.1207676,\n",
       "  4.1217036,\n",
       "  4.121556,\n",
       "  4.1220613,\n",
       "  4.113785,\n",
       "  4.1244617,\n",
       "  4.1224647,\n",
       "  4.113756,\n",
       "  4.1132717,\n",
       "  4.1098924,\n",
       "  4.1060553,\n",
       "  4.1040254,\n",
       "  4.102885,\n",
       "  4.1042166,\n",
       "  4.102471,\n",
       "  3.8400981,\n",
       "  3.7095323,\n",
       "  3.5731258,\n",
       "  3.4833543,\n",
       "  3.584402,\n",
       "  3.641061,\n",
       "  3.6805854,\n",
       "  3.7072096,\n",
       "  3.6606898,\n",
       "  3.6624706,\n",
       "  3.6848755,\n",
       "  3.7035408,\n",
       "  3.7447379,\n",
       "  3.7574973,\n",
       "  3.7765825,\n",
       "  3.7691512,\n",
       "  3.7697647,\n",
       "  3.7659178,\n",
       "  3.7922359,\n",
       "  3.820362,\n",
       "  3.8423953,\n",
       "  3.8425643,\n",
       "  3.834681,\n",
       "  3.8396683,\n",
       "  3.8429406,\n",
       "  3.8248065,\n",
       "  3.8098857,\n",
       "  3.820902,\n",
       "  3.8255177,\n",
       "  3.8122544,\n",
       "  3.8088338,\n",
       "  3.8291512,\n",
       "  3.831479,\n",
       "  3.8341548,\n",
       "  3.8352635,\n",
       "  3.8530655,\n",
       "  3.858108,\n",
       "  3.8646626,\n",
       "  3.8748279,\n",
       "  3.8876987,\n",
       "  3.8962305,\n",
       "  3.8991783,\n",
       "  3.90301,\n",
       "  3.889641,\n",
       "  3.8935697,\n",
       "  3.891338,\n",
       "  3.8980424,\n",
       "  3.8957279,\n",
       "  3.9062965,\n",
       "  3.908258,\n",
       "  3.9146602,\n",
       "  3.90544,\n",
       "  3.8997808,\n",
       "  3.8980238,\n",
       "  3.9044151,\n",
       "  3.9009366,\n",
       "  3.9056084,\n",
       "  3.9039114,\n",
       "  3.900964,\n",
       "  3.9009337,\n",
       "  3.9005039,\n",
       "  3.8987255,\n",
       "  3.90949,\n",
       "  3.9055014,\n",
       "  3.9083655,\n",
       "  3.9071507,\n",
       "  3.9061255,\n",
       "  3.9077952,\n",
       "  3.910345,\n",
       "  3.9141414,\n",
       "  3.9107897,\n",
       "  3.9099455,\n",
       "  3.9092536,\n",
       "  3.911625,\n",
       "  3.9082482,\n",
       "  3.909568,\n",
       "  3.910294,\n",
       "  3.908166,\n",
       "  3.9001315,\n",
       "  4.1642957,\n",
       "  4.1552467,\n",
       "  3.9785748,\n",
       "  4.0139527,\n",
       "  3.939361,\n",
       "  3.9458685,\n",
       "  3.957648,\n",
       "  3.9341958,\n",
       "  3.897552,\n",
       "  3.9392853,\n",
       "  3.8970916,\n",
       "  3.8834848,\n",
       "  3.909365,\n",
       "  3.892716,\n",
       "  3.8790305,\n",
       "  3.889782,\n",
       "  3.8714168,\n",
       "  3.8604774,\n",
       "  3.838858,\n",
       "  3.84283,\n",
       "  3.836572,\n",
       "  3.8311906,\n",
       "  3.8421357,\n",
       "  3.8421123,\n",
       "  3.84931,\n",
       "  3.8454225,\n",
       "  3.8382864,\n",
       "  3.8280237,\n",
       "  3.8265862,\n",
       "  3.8310344,\n",
       "  3.8292742,\n",
       "  3.812964,\n",
       "  3.8080401,\n",
       "  3.8105164,\n",
       "  3.81038,\n",
       "  3.7908506,\n",
       "  3.7777846,\n",
       "  3.77149,\n",
       "  3.7792213,\n",
       "  3.779348,\n",
       "  3.7909386,\n",
       "  3.7964172,\n",
       "  3.8066065,\n",
       "  3.8030577,\n",
       "  3.7964833,\n",
       "  3.7922873,\n",
       "  3.7904422,\n",
       "  3.7920983,\n",
       "  3.7815661,\n",
       "  3.782858,\n",
       "  3.7899323,\n",
       "  3.7876015,\n",
       "  3.788988,\n",
       "  3.78508,\n",
       "  3.7839115,\n",
       "  3.7905133,\n",
       "  3.7993126,\n",
       "  3.7993324,\n",
       "  3.799582,\n",
       "  3.8070824,\n",
       "  3.8045406,\n",
       "  3.8054388,\n",
       "  3.804227,\n",
       "  3.80902,\n",
       "  3.8054411,\n",
       "  3.8049126,\n",
       "  3.8061569,\n",
       "  3.7980382,\n",
       "  3.8016005,\n",
       "  3.805191,\n",
       "  3.8008792,\n",
       "  3.8010397,\n",
       "  3.8073332,\n",
       "  3.8075035,\n",
       "  3.8047464,\n",
       "  3.8000166,\n",
       "  3.7993417,\n",
       "  3.8014314,\n",
       "  3.791124,\n",
       "  3.9952981,\n",
       "  3.7365985,\n",
       "  3.7472365,\n",
       "  3.7945971,\n",
       "  3.7550976,\n",
       "  3.7595003,\n",
       "  3.7674563,\n",
       "  3.7764862,\n",
       "  3.7906473,\n",
       "  3.7878299,\n",
       "  3.7905838,\n",
       "  3.7680054,\n",
       "  3.7671804,\n",
       "  3.774772,\n",
       "  3.7802155,\n",
       "  3.7821689,\n",
       "  3.8127742,\n",
       "  3.829974,\n",
       "  3.84507,\n",
       "  3.8488917,\n",
       "  3.8461041,\n",
       "  3.848005,\n",
       "  3.860124,\n",
       "  3.8487587,\n",
       "  3.8442078,\n",
       "  3.850857,\n",
       "  3.8496718,\n",
       "  3.8469086,\n",
       "  3.8384614,\n",
       "  3.8269148,\n",
       "  3.8181026,\n",
       "  3.8046799,\n",
       "  3.7943928,\n",
       "  3.7902334,\n",
       "  3.796936,\n",
       "  3.788648,\n",
       "  3.7959356,\n",
       "  3.797686,\n",
       "  3.793846,\n",
       "  3.8040366,\n",
       "  3.8054771,\n",
       "  3.8250422,\n",
       "  3.8300362,\n",
       "  3.829486,\n",
       "  3.8363051,\n",
       "  3.8321373,\n",
       "  3.8427455,\n",
       "  3.8408368,\n",
       "  3.837961,\n",
       "  3.851069,\n",
       "  3.8478737,\n",
       "  3.8441722,\n",
       "  3.8521144,\n",
       "  3.8533447,\n",
       "  3.8559442,\n",
       "  3.852411,\n",
       "  3.8471525,\n",
       "  3.8449938,\n",
       "  3.8491187,\n",
       "  3.849997,\n",
       "  3.8514922,\n",
       "  3.8471699,\n",
       "  3.842838,\n",
       "  3.844081,\n",
       "  3.8466735,\n",
       "  3.8413477,\n",
       "  3.8323255,\n",
       "  3.8362179,\n",
       "  3.8370101,\n",
       "  3.8387172,\n",
       "  3.8308308,\n",
       "  3.8376431,\n",
       "  3.834978,\n",
       "  3.8256288,\n",
       "  3.8216698,\n",
       "  3.8174279,\n",
       "  3.8205914,\n",
       "  3.8116114,\n",
       "  3.8234496,\n",
       "  3.9885674,\n",
       "  3.8158474,\n",
       "  3.845254,\n",
       "  3.8314505,\n",
       "  3.807949,\n",
       "  3.711634,\n",
       "  3.7590954,\n",
       "  3.7977533,\n",
       "  3.782681,\n",
       "  3.774908,\n",
       "  3.8070366,\n",
       "  3.7831147,\n",
       "  3.777626,\n",
       "  3.7580478,\n",
       "  3.7614298,\n",
       "  3.758882,\n",
       "  3.7577448,\n",
       "  3.7314177,\n",
       "  3.73502,\n",
       "  3.737449,\n",
       "  3.7237437,\n",
       "  3.7092116,\n",
       "  3.6975951,\n",
       "  3.715144,\n",
       "  3.739013,\n",
       "  3.7411337,\n",
       "  3.7568219,\n",
       "  3.756944,\n",
       "  3.7515407,\n",
       "  3.7609153,\n",
       "  3.7662928,\n",
       "  3.7697072,\n",
       "  3.7952752,\n",
       "  3.7861776,\n",
       "  3.7748055,\n",
       "  3.7672,\n",
       "  3.760607,\n",
       "  3.7570226,\n",
       "  3.7569685,\n",
       "  3.7618308,\n",
       "  3.7624347,\n",
       "  3.7605724,\n",
       "  3.7602487,\n",
       "  3.7557847,\n",
       "  3.7678783,\n",
       "  3.7609806,\n",
       "  3.7631218,\n",
       "  3.7634718,\n",
       "  3.763374,\n",
       "  3.7622046,\n",
       "  3.7618454,\n",
       "  3.7597184,\n",
       "  3.765576,\n",
       "  3.7699206,\n",
       "  3.761101,\n",
       "  3.7539177,\n",
       "  3.764494,\n",
       "  3.7647688,\n",
       "  3.7635171,\n",
       "  3.7614887,\n",
       "  3.7583113,\n",
       "  3.757825,\n",
       "  3.7545226,\n",
       "  3.7526684,\n",
       "  3.7521312,\n",
       "  3.746389,\n",
       "  3.7458344,\n",
       "  3.745933,\n",
       "  3.740379,\n",
       "  3.7435467,\n",
       "  3.7480502,\n",
       "  3.750188,\n",
       "  3.7513,\n",
       "  3.7495353,\n",
       "  3.7499394,\n",
       "  3.7522566,\n",
       "  3.7591133,\n",
       "  3.755808,\n",
       "  3.7445273,\n",
       "  4.042598,\n",
       "  3.9068484,\n",
       "  3.70672,\n",
       "  3.7651205,\n",
       "  3.738316,\n",
       "  3.7915955,\n",
       "  3.7902753,\n",
       "  3.7697887,\n",
       "  3.7784395,\n",
       "  3.7508273,\n",
       "  3.7243395,\n",
       "  3.7310455,\n",
       "  3.728146,\n",
       "  3.6970882,\n",
       "  3.6803563,\n",
       "  3.6958103,\n",
       "  3.705718,\n",
       "  3.6740215,\n",
       "  3.6799047,\n",
       "  3.6985335,\n",
       "  3.7212148,\n",
       "  3.7266195,\n",
       "  3.6958814,\n",
       "  3.7032,\n",
       "  3.7014391,\n",
       "  3.6985838,\n",
       "  3.6910803,\n",
       "  3.6881003,\n",
       "  3.6742933,\n",
       "  3.6737137,\n",
       "  3.6741786,\n",
       "  3.6743765,\n",
       "  3.67178,\n",
       "  3.6714191,\n",
       "  3.6555727,\n",
       "  3.645299,\n",
       "  3.6422024,\n",
       "  3.6392095,\n",
       "  3.6318457,\n",
       "  3.6286225,\n",
       "  3.6332638,\n",
       "  3.6318781,\n",
       "  3.631775,\n",
       "  3.6225653,\n",
       "  3.6178012,\n",
       "  3.6163177,\n",
       "  3.612312,\n",
       "  3.6033833,\n",
       "  3.598995,\n",
       "  3.6007693,\n",
       "  3.6068618,\n",
       "  3.6059253,\n",
       "  3.6144712,\n",
       "  3.6153502,\n",
       "  3.613887,\n",
       "  3.614672,\n",
       "  3.6162372,\n",
       "  3.616692,\n",
       "  3.6124957,\n",
       "  3.620357,\n",
       "  3.6250134,\n",
       "  3.6299267,\n",
       "  3.6278512,\n",
       "  3.627192,\n",
       "  3.628215,\n",
       "  3.635147,\n",
       "  3.6307125,\n",
       "  3.6338146,\n",
       "  3.6308641,\n",
       "  3.6278648,\n",
       "  3.6297634,\n",
       "  3.6345356,\n",
       "  3.6378913,\n",
       "  3.6396856,\n",
       "  3.637535,\n",
       "  3.639574,\n",
       "  3.6382475,\n",
       "  3.6376348,\n",
       "  3.6340213],\n",
       " 'mean_val_loss': [1.9939928, 1.8412073, 1.844857, 1.930764, 2.0103106],\n",
       " 'min_val_loss': 1.8412073,\n",
       " 'test_loss': [tensor(2.1238),\n",
       "  tensor(1.8693),\n",
       "  tensor(1.9509),\n",
       "  tensor(1.8589),\n",
       "  tensor(2.0245)],\n",
       " 'train_time': 593.6578595638275,\n",
       " 'trainargs': {'activation': 'ReLU',\n",
       "  'batch_size': 512,\n",
       "  'checkpoint': True,\n",
       "  'checkpoint_path': '/content/gdrive/My Drive/rxn_ebm/',\n",
       "  'dropout': 0.5,\n",
       "  'early_stop': True,\n",
       "  'epochs': 50,\n",
       "  'expt_name': '2048_1layer_1neg_rad2_ReLU',\n",
       "  'fp_radius': 2,\n",
       "  'fp_type': 'sep',\n",
       "  'hidden_sizes': [256],\n",
       "  'learning_rate': 1e-05,\n",
       "  'min_delta': 1e-05,\n",
       "  'model': 'FF_sep',\n",
       "  'model_seed': 1337,\n",
       "  'num_neg': 1,\n",
       "  'optimizer': torch.optim.adam.Adam,\n",
       "  'output_size': 1,\n",
       "  'path_to_pickle': '/content/clean_rxn_50k_nomap_noreagent.pickle',\n",
       "  'patience': 3,\n",
       "  'prodfp_size': 2048,\n",
       "  'random_seed': 0,\n",
       "  'rctfp_size': 2048}}"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pvI5jZOcwEnw",
    "outputId": "d63f1b3c-dfc0-4a3f-e740-2812e3ec28bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:48<00:00,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_time: 7941.052913427353\n",
      "test_loss: [tensor(3.6462), tensor(4.0916), tensor(3.9566), tensor(3.9063), tensor(3.8079)]\n",
      "mean_test_loss: 3.8817272186279297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stats = test(model, stats, trainargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvDHRmfi3ZaF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "twEVWkj63ZZ5"
   ],
   "name": "rad = 3 num_neg = 5 Feedforward_+_diffFP_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
