{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSKTT4aD3ZZh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import rdqueries # faster than iterating atoms https://sourceforge.net/p/rdkit/mailman/message/34538007/ \n",
    "from rdkit.Chem.rdchem import Atom\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re \n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o12DGGe3ZZ2"
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rxns = [\n",
    "    '[CH:2](=[O:3])[NH:4][c:5]1[c:6]([CH2:7][CH2:8][c:9]2[n+:10]([CH3:15])[cH:11][cH:12][cH:13][cH:14]2)[cH:16][c:17]([O:20][CH3:21])[cH:18][cH:19]1>[I-].[I-].C[n+]1ccccc1C=Cc1ccccc1[N+](=O)[O-]>[CH:2](=[O:3])[NH:4][c:5]1[c:6]([CH2:7][CH2:8][CH:9]2[N:10]([CH3:15])[CH2:11][CH2:12][CH2:13][CH2:14]2)[cH:16][c:17]([O:20][CH3:21])[cH:18][cH:19]1',\n",
    " 'Cl[c:2]1[c:3]([C:4](=[O:5])[c:6]2[cH:7][c:8]([CH:13]([C:14](=[O:15])[OH:16])[CH3:17])[cH:9][cH:10][c:11]2[OH:12])[cH:18][cH:19][cH:20][n:21]1>O.[Cu].[Cu](I)I.[OH-].[Na+]>[c:2]12[c:3]([c:4](=[O:5])[c:6]3[cH:7][c:8]([CH:13]([C:14](=[O:15])[OH:16])[CH3:17])[cH:9][cH:10][c:11]3[o:12]1)[cH:18][cH:19][cH:20][n:21]2',\n",
    " '[CH3:3][c:4]1[c:5]([OH:12])[c:6]([CH3:11])[cH:7][cH:8][c:9]1[CH3:10].CC(O)=[O:15]>II>[CH3:3][C:4]1=[C:9]([CH3:10])[C:8](=[O:15])[CH:7]=[C:6]([CH3:11])[C:5]1=[O:12]',\n",
    " '[CH3:1][O:2][CH:3]([C:4]#[CH:5])[CH2:6][CH2:7][CH2:8][CH2:9][CH3:10].I[I:29]>CC(C)C(C)BC(C)C(C)C.C[N+](C)(C)[O-].[OH-].[Na+]>[CH3:1][O:2][CH:3](/[CH:4]=[CH:5]/[I:29])[CH2:6][CH2:7][CH2:8][CH2:9][CH3:10]',\n",
    " 'O=[C:4]1[CH:3]([CH2:1][CH3:2])[CH2:8][CH2:7][CH2:6][CH:5]1[CH3:9].[CH3:11][CH:12]([CH2:13][O:14][CH3:15])[NH2:16]>C1(C)C=CC=CC=1.CCOCC.[Ti](Cl)(Cl)(Cl)Cl>[CH2:1]([CH3:2])[CH:3]1[C:4](=[N:16][CH:12]([CH3:11])[CH2:13][O:14][CH3:15])[CH:5]([CH3:9])[CH2:6][CH2:7][CH2:8]1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "def create_rxn_MorganFP(rxn_smi, fp_type='diff', \n",
    "                        radius=2, rctfp_size=16384, prodfp_size=16384, \n",
    "                        max_rcts=4, \n",
    "                        useChirality=True, dtype='int8'):\n",
    "    '''\n",
    "    fp_type: 'diff' or 'sep', \n",
    "    'diff' (difference):\n",
    "    Creates reaction MorganFP following Schneider et al in J. Chem. Inf. Model. 2015, 55, 1, 39–53\n",
    "    reactionFP = productFP - sum(reactantFPs)\n",
    "    \n",
    "    'sep' (separate):\n",
    "    Creates separate reactantsFP and productFP following Gao et al in ACS Cent. Sci. 2018, 4, 11, 1465–1476\n",
    "    '''\n",
    "    # initialise empty fp numpy arrays\n",
    "    if fp_type == 'diff':\n",
    "        diff_fp = np.empty(fp_size, dtype = dtype)\n",
    "    elif fp_type == 'sep':\n",
    "        rcts_fp = np.empty(rctfp_size, dtype = dtype)\n",
    "        prod_fp = np.empty(prodfp_size, dtype = dtype)\n",
    "    elif fp_type == 'precomp':\n",
    "        rct_fps = np.empty((max_rcts, rctfp_size)) \n",
    "        prod_fp = np.empty((1, rctfp_size), dtype = dtype)\n",
    "        assert rctfp_size == prodfp_size, 'rctfp_size != prodfp_size, unable to build sparse matrix!!!'\n",
    "    else:\n",
    "        print('ERROR: fp_type not recognised!')\n",
    "        return\n",
    "    \n",
    "    # create product FP\n",
    "    prod_mol = Chem.MolFromSmiles(rxn_smi.split('>')[-1])\n",
    "    try:\n",
    "        prod_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                        mol=prod_mol, radius=radius, nBits=prodfp_size, useChirality=useChirality)\n",
    "        if fp_type == 'precomp':\n",
    "            DataStructs.ConvertToNumpyArray(prod_fp_bit, prod_fp[0, :])\n",
    "        else:      # on-the-fly creation of MorganFP during training  \n",
    "            fp = np.empty(prodfp_size, dtype = dtype)   # temporarily store numpy array as fp \n",
    "            DataStructs.ConvertToNumpyArray(prod_fp_bit, fp)\n",
    "            if fp_type == 'diff':\n",
    "                diff_fp += fp\n",
    "            elif fp_type == 'sep':\n",
    "                prod_fp = fp\n",
    "    except Exception as e:\n",
    "        print(\"Cannot build product fp due to {}\".format(e))\n",
    "        return\n",
    "                                  \n",
    "    # create reactant FPs, subtracting each from product FP\n",
    "    rcts_smi = rxn_smi.split('>')[0].split('.')\n",
    "    for i, rct_smi in enumerate(rcts_smi):\n",
    "        rct_mol = Chem.MolFromSmiles(rct_smi)\n",
    "        try:\n",
    "            rct_fp_bit = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                            mol=rct_mol, radius=radius, nBits=rctfp_size, useChirality=useChirality)\n",
    "            if fp_type == 'precomp':\n",
    "                DataStructs.ConvertToNumpyArray(rct_fp_bit, rct_fps[i, :])\n",
    "            else:     # on-the-fly creation of MorganFP during training  \n",
    "                fp = np.empty(rctfp_size, dtype = dtype)\n",
    "                DataStructs.ConvertToNumpyArray(rct_fp_bit, fp)\n",
    "                if fp_type == 'diff':\n",
    "                    diff_fp -= fp\n",
    "                elif fp_type == 'sep':\n",
    "                    rcts_fp += fp\n",
    "        except Exception as e:\n",
    "            print(\"Cannot build reactant fp due to {}\".format(e))\n",
    "            return\n",
    "    \n",
    "    if fp_type == 'diff':\n",
    "        return diff_fp\n",
    "    elif fp_type == 'sep':\n",
    "        return np.concatenate([rcts_fp, prod_fp])\n",
    "    elif fp_type == 'precomp':\n",
    "        rct_fps = rct_fps.reshape(1, -1) # flatten into 1 long row-array \n",
    "        return np.concatenate([rct_fps, prod_fp], axis=1), len(rcts_smi)\n",
    "    \n",
    "    \n",
    "def make_sparse_FP(rxn_smi_dataset, radius, fp_size, max_rcts, \n",
    "                   useChirality=True, dtype='int8', toprint=False, every=10000):\n",
    "    '''\n",
    "    rxn_smi_dataset: expects a list of rxn_smi (strings)\n",
    "    returns: a sparse matrix of reaction fingerprints + a list of num_rcts per rxn\n",
    "    '''\n",
    "    sparse_fps, list_num_rcts = [], []   \n",
    "    for i, rxn_smi in enumerate(rxn_smi_dataset):          \n",
    "        rxn_fp, num_rcts = create_rxn_MorganFP(rxn_smi, fp_type='precomp', \n",
    "                            radius=radius, rctfp_size=fp_size, prodfp_size=fp_size, \n",
    "                            max_rcts=max_rcts, \n",
    "                            useChirality=useChirality, dtype=dtype)\n",
    "        rxn_fp_sparse = sparse.csr_matrix(rxn_fp)\n",
    "        sparse_fps.append(rxn_fp_sparse)\n",
    "        list_num_rcts.append(num_rcts)\n",
    "        if toprint and i%every == 0:\n",
    "            print('Processed: {} rxn SMILES'.format(i))\n",
    "\n",
    "    return sparse.vstack(sparse_fps), list_num_rcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/clean_rxn_50k_nomap_noreagent.pickle', 'rb') as handle:\n",
    "    clean_rxn = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_rxn_sparse_fp = {'train': None, 'valid': None, 'test': None}\n",
    "clean_rxn_sparse_fp_numrcts = {'train': None, 'valid': None, 'test': None}\n",
    "\n",
    "for key in clean_rxn.keys():\n",
    "    print('\\nMaking sparse FPs for {}'.format(key))\n",
    "    fp_sparse_matrix, list_num_rcts = make_sparse_FP(clean_rxn[key], 3, 4096, max_rcts=4, \n",
    "                                       useChirality=True, dtype='int8', toprint=True, every=10000)\n",
    "    clean_rxn_sparse_fp[key] = fp_sparse_matrix\n",
    "    clean_rxn_sparse_fp_numrcts[key] = list_num_rcts\n",
    "\n",
    "# takes about 2 mins 15 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16384 FP np arrays are massive, saving to disk causes memory error (>8 GB). need to convert to sparse csr matrix then save as .npz \n",
    "- for 4096 x (4 max rcts + 1 prod) sparse matrix, storage size is about 80 MB for USPTO-50k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/clean_rxn_50k_sparse_FPs.pickle', 'wb') as handle:\n",
    "    pickle.dump(clean_rxn_sparse_fp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.getcwd()+'/clean_rxn_50k_sparse_FPs_numrcts.pickle', 'wb') as handle:\n",
    "    pickle.dump(clean_rxn_sparse_fp_numrcts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .npz takes up less space (9 MB) than .pickle (80 MB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(os.getcwd()+'/clean_rxn_50k_sparse_FPs_train.npz', clean_rxn_sparse_fp['train'])\n",
    "sparse.save_npz(os.getcwd()+'/clean_rxn_50k_sparse_FPs_valid.npz', clean_rxn_sparse_fp['valid'])\n",
    "sparse.save_npz(os.getcwd()+'/clean_rxn_50k_sparse_FPs_test.npz', clean_rxn_sparse_fp['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try on USPTO_STEREO\n",
    "- max_rcts = 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/USPTO_STEREO_pickles/clean_rxn_nomap_noreagent.pickle', 'rb') as handle:\n",
    "    clean_rxn = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making sparse FPs for train\n",
      "Processed: 0 rxn SMILES\n",
      "Processed: 10000 rxn SMILES\n",
      "Processed: 20000 rxn SMILES\n",
      "Processed: 30000 rxn SMILES\n",
      "Processed: 40000 rxn SMILES\n",
      "Processed: 50000 rxn SMILES\n",
      "Processed: 60000 rxn SMILES\n",
      "Processed: 70000 rxn SMILES\n",
      "Processed: 80000 rxn SMILES\n",
      "Processed: 90000 rxn SMILES\n",
      "Processed: 100000 rxn SMILES\n",
      "Processed: 110000 rxn SMILES\n",
      "Processed: 120000 rxn SMILES\n",
      "Processed: 130000 rxn SMILES\n",
      "Processed: 140000 rxn SMILES\n",
      "Processed: 150000 rxn SMILES\n",
      "Processed: 160000 rxn SMILES\n",
      "Processed: 170000 rxn SMILES\n",
      "Processed: 180000 rxn SMILES\n",
      "Processed: 190000 rxn SMILES\n",
      "Processed: 200000 rxn SMILES\n",
      "Processed: 210000 rxn SMILES\n",
      "Processed: 220000 rxn SMILES\n",
      "Processed: 230000 rxn SMILES\n",
      "Processed: 240000 rxn SMILES\n",
      "Processed: 250000 rxn SMILES\n",
      "Processed: 260000 rxn SMILES\n",
      "Processed: 270000 rxn SMILES\n",
      "Processed: 280000 rxn SMILES\n",
      "Processed: 290000 rxn SMILES\n",
      "Processed: 300000 rxn SMILES\n",
      "Processed: 310000 rxn SMILES\n",
      "Processed: 320000 rxn SMILES\n",
      "Processed: 330000 rxn SMILES\n",
      "Processed: 340000 rxn SMILES\n",
      "Processed: 350000 rxn SMILES\n",
      "Processed: 360000 rxn SMILES\n",
      "Processed: 370000 rxn SMILES\n",
      "Processed: 380000 rxn SMILES\n",
      "Processed: 390000 rxn SMILES\n",
      "Processed: 400000 rxn SMILES\n",
      "Processed: 410000 rxn SMILES\n",
      "Processed: 420000 rxn SMILES\n",
      "Processed: 430000 rxn SMILES\n",
      "Processed: 440000 rxn SMILES\n",
      "Processed: 450000 rxn SMILES\n",
      "Processed: 460000 rxn SMILES\n",
      "Processed: 470000 rxn SMILES\n",
      "Processed: 480000 rxn SMILES\n",
      "Processed: 490000 rxn SMILES\n",
      "Processed: 500000 rxn SMILES\n",
      "Processed: 510000 rxn SMILES\n",
      "Processed: 520000 rxn SMILES\n",
      "Processed: 530000 rxn SMILES\n",
      "Processed: 540000 rxn SMILES\n",
      "Processed: 550000 rxn SMILES\n",
      "Processed: 560000 rxn SMILES\n",
      "Processed: 570000 rxn SMILES\n",
      "Processed: 580000 rxn SMILES\n",
      "Processed: 590000 rxn SMILES\n",
      "Processed: 600000 rxn SMILES\n",
      "Processed: 610000 rxn SMILES\n",
      "Processed: 620000 rxn SMILES\n",
      "Processed: 630000 rxn SMILES\n",
      "Processed: 640000 rxn SMILES\n",
      "Processed: 650000 rxn SMILES\n",
      "Processed: 660000 rxn SMILES\n",
      "Processed: 670000 rxn SMILES\n",
      "Processed: 680000 rxn SMILES\n",
      "Processed: 690000 rxn SMILES\n",
      "Processed: 700000 rxn SMILES\n",
      "Processed: 710000 rxn SMILES\n",
      "Processed: 720000 rxn SMILES\n",
      "Processed: 730000 rxn SMILES\n",
      "Processed: 740000 rxn SMILES\n",
      "Processed: 750000 rxn SMILES\n",
      "Processed: 760000 rxn SMILES\n",
      "Processed: 770000 rxn SMILES\n",
      "Processed: 780000 rxn SMILES\n",
      "Processed: 790000 rxn SMILES\n",
      "Processed: 800000 rxn SMILES\n",
      "Processed: 810000 rxn SMILES\n",
      "Processed: 820000 rxn SMILES\n",
      "Processed: 830000 rxn SMILES\n",
      "Processed: 840000 rxn SMILES\n",
      "Processed: 850000 rxn SMILES\n",
      "Processed: 860000 rxn SMILES\n",
      "\n",
      "Making sparse FPs for valid\n",
      "Processed: 0 rxn SMILES\n",
      "Processed: 10000 rxn SMILES\n",
      "Processed: 20000 rxn SMILES\n",
      "Processed: 30000 rxn SMILES\n",
      "Processed: 40000 rxn SMILES\n",
      "\n",
      "Making sparse FPs for test\n",
      "Processed: 0 rxn SMILES\n",
      "Processed: 10000 rxn SMILES\n",
      "Processed: 20000 rxn SMILES\n",
      "Processed: 30000 rxn SMILES\n",
      "Processed: 40000 rxn SMILES\n",
      "Wall time: 34min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_rxn_sparse_fp = {'train': None, 'valid': None, 'test': None}\n",
    "clean_rxn_sparse_fp_numrcts = {'train': None, 'valid': None, 'test': None}\n",
    "\n",
    "for key in clean_rxn.keys():\n",
    "    print('\\nMaking sparse FPs for {}'.format(key))\n",
    "    fp_sparse_matrix, list_num_rcts = make_sparse_FP(clean_rxn[key], 3, 4096, max_rcts=9, \n",
    "                                       useChirality=True, dtype='int8', toprint=True, every=10000)\n",
    "    clean_rxn_sparse_fp[key] = fp_sparse_matrix\n",
    "    clean_rxn_sparse_fp_numrcts[key] = list_num_rcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<48165x40960 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13412426 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rxn_sparse_fp['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(os.getcwd()+'/USPTO_STEREO_pickles/clean_rxn_sparse_FPs_train.npz', clean_rxn_sparse_fp['train'])\n",
    "sparse.save_npz(os.getcwd()+'/USPTO_STEREO_pickles/clean_rxn_sparse_FPs_valid.npz', clean_rxn_sparse_fp['valid'])\n",
    "sparse.save_npz(os.getcwd()+'/USPTO_STEREO_pickles/clean_rxn_sparse_FPs_test.npz', clean_rxn_sparse_fp['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/USPTO_STEREO_pickles/clean_rxn_sparse_FPs_numrcts.pickle', 'wb') as handle:\n",
    "    pickle.dump(clean_rxn_sparse_fp_numrcts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "twEVWkj63ZZ5"
   ],
   "name": "Feedforward_+_sepFP_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
