{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMGN51DE3ZZg"
   },
   "source": [
    "### To do:  \n",
    "- collate_fn & num_workers \n",
    "- Bayesian optimisation \n",
    "- logging hyperparameter optimisation (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "B9nA-HrcmbQT",
    "outputId": "365524f5-a556-4ddd-9482-ae052f9f2350"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# !git clone https://github.com/facebookresearch/pysparnn.git\n",
    "# # cd pysparnn # cd only works on Colab if it's the only line of code in the cell \n",
    "# prev_cwd = Path.cwd()\n",
    "# os.chdir('pysparnn')\n",
    "# try:\n",
    "#     !python setup.py install\n",
    "# finally:\n",
    "#     os.chdir(prev_cwd)\n",
    "#     # cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c1pxoCjT4CbP",
    "outputId": "8b706056-57f3-40a9-f9cc-b6456d5972e4"
   },
   "outputs": [],
   "source": [
    "# !wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# !chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "# !bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# !conda install --quiet -y -c conda-forge python=3.7\n",
    "# !conda install --quiet -y -c conda-forge rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "87OYfp5T4QDS",
    "outputId": "a9943908-407f-4e44-f083-7541d66a488b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MR_BynDpmbQe"
   },
   "outputs": [],
   "source": [
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_sparse_FPs_numrcts_train.npz' '/content/'\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_sparse_FPs_numrcts_valid.npz' '/content/'\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/clean_rxn_50k_sparse_FPs_numrcts_test.npz' '/content/'\n",
    "# # !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/50k_allmols_sparse_FP_clusterIndex.bin' '/content/'\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/50k_allmols_sparse_FP_MONOclusterIndex.bin' '/content/'\n",
    "# !cp '/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/50k_all_mols_sparse_FPs.npz' '/content/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1rNXJq4mbQh"
   },
   "source": [
    "### Change LOCAL & cosine depending on your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8Q1rtww36JU"
   },
   "outputs": [],
   "source": [
    "LOCAL = False # CHANGE THIS \n",
    "cosine = True # CHANGE THIS \n",
    " \n",
    "if LOCAL: \n",
    "    checkpoint_folder = 'checkpoints/'\n",
    "    base_path = 'USPTO_50k_data/clean_rxn_50k_sparse_FPs_numrcts'\n",
    "    if cosine:\n",
    "        cluster_path = 'USPTO_50k_data/50k_allmols_sparse_FP_MONOclusterIndex.bin'\n",
    "        sparseFP_vocab_path = 'USPTO_50k_data/50k_all_mols_sparse_FPs.npz'\n",
    "else: # colab \n",
    "    checkpoint_folder = '/content/gdrive/My Drive/rxn_ebm/checkpoints/' \n",
    "    base_path = '/content/clean_rxn_50k_sparse_FPs_numrcts'\n",
    "    if cosine:\n",
    "        cluster_path = '/content/50k_allmols_sparse_FP_MONOclusterIndex.bin' \n",
    "        sparseFP_vocab_path = '/content/50k_all_mols_sparse_FPs.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSKTT4aD3ZZh"
   },
   "outputs": [],
   "source": [
    "import pysparnn.cluster_index as ci\n",
    "\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/') \n",
    "# for Colab \n",
    "import os\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import rdqueries # faster than iterating atoms https://sourceforge.net/p/rdkit/mailman/message/34538007/ \n",
    "from rdkit.Chem.rdchem import Atom\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "import csv\n",
    "import re \n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMIpqIVk3ZZs"
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfFuy7g03ZZs"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_activation_function(activation: str) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Gets an activation function module given the name of the activation.\n",
    "    Supports:\n",
    "    * :code:`ReLU`\n",
    "    * :code:`LeakyReLU`\n",
    "    * :code:`PReLU`\n",
    "    * :code:`tanh`\n",
    "    * :code:`SELU`\n",
    "    * :code:`ELU`\n",
    "    :param activation: The name of the activation function.\n",
    "    :return: The activation function module.\n",
    "    \"\"\"\n",
    "    if activation == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'LeakyReLU':\n",
    "        return nn.LeakyReLU(0.1)\n",
    "    elif activation == 'PReLU':\n",
    "        return nn.PReLU()\n",
    "    elif activation == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif activation == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif activation == 'ELU':\n",
    "        return nn.ELU()\n",
    "    else:\n",
    "        raise ValueError(f'Activation \"{activation}\" not supported.')\n",
    "    \n",
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Initializes the weights of a model in place.\n",
    "    :param model: An PyTorch model.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant_(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1Cfy0AF3ZZv"
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxvJUWjr3ZZw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FF_ebm(nn.Module):\n",
    "    '''\n",
    "    trainargs: dictionary containing hyperparameters to be optimised, \n",
    "    hidden_sizes must be a list e.g. [1024, 512, 256]\n",
    "    \n",
    "    To do: bayesian optimisation\n",
    "    '''\n",
    "    def __init__(self, trainargs):\n",
    "        super(FF_ebm, self).__init__()\n",
    "        self.output_size = trainargs['output_size']\n",
    "        self.num_layers = len(trainargs['hidden_sizes']) + 1\n",
    "\n",
    "        if trainargs['model'] == 'FF_sep':\n",
    "          self.input_dim = trainargs['rctfp_size'] + trainargs['prodfp_size'] # will be rctfp_size + prodfp_size for FF_sep\n",
    "        elif trainargs['model'] == 'FF_diff':\n",
    "          self.input_dim = trainargs['rctfp_size']\n",
    "          assert trainargs['rctfp_size'] == trainargs['prodfp_size'], 'rctfp_size != prodfp_size, unable to make difference FPs!!!'\n",
    "\n",
    "        self.create_ffn(trainargs)\n",
    "        initialize_weights(self)  # is it necessary to initialize weights?? \n",
    "    \n",
    "    def create_ffn(self, trainargs):\n",
    "        '''\n",
    "        Creates feed-forward network using trainargs dict\n",
    "        '''\n",
    "        dropout = nn.Dropout(trainargs['dropout'])\n",
    "        activation = get_activation_function(trainargs['activation'])\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, self.output_size)\n",
    "            ]\n",
    "        else:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(self.input_dim, trainargs['hidden_sizes'][0])\n",
    "            ]\n",
    "            \n",
    "            # intermediate hidden layers \n",
    "            for i, layer in enumerate(range(self.num_layers - 2)):\n",
    "                ffn.extend([\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    nn.Linear(trainargs['hidden_sizes'][i], trainargs['hidden_sizes'][i+1]),\n",
    "                ])\n",
    "                \n",
    "            # last hidden layer\n",
    "            ffn.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(trainargs['hidden_sizes'][-1], self.output_size),\n",
    "            ])\n",
    "\n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        '''\n",
    "        Runs FF_ebm on input\n",
    "        \n",
    "        batch: a N x K x 1 tensor of N training samples, where each sample contains \n",
    "        a positive rxn on the first column, and K-1 negative rxn on subsequent columns \n",
    "        supplied by DataLoader on custom ReactionDataset \n",
    "        '''\n",
    "        energy_scores = self.ffn(batch) # tensor of size N x K x 1\n",
    "        return energy_scores.squeeze(dim=-1)  # scores: N x K after squeezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7EzzESW3ZZz"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeAWhxLw3ZZz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class Run():\n",
    "    '''\n",
    "    epochs are 1-indexed (i.e. start from 1, 2, 3 ... not 0, 1, 2 ...)\n",
    "    if load_checkpoint == True, load_optimizer, load_stats & begin_epoch must be provided \n",
    "    '''\n",
    "    def __init__(self, model, trainargs,\n",
    "                 load_optimizer=None, load_checkpoint=False, load_stats=None, begin_epoch=None):\n",
    "        self.device = trainargs['device']\n",
    "        model = model.to(self.device)\n",
    "        self.model = model\n",
    "        self.trainargs = trainargs \n",
    "        self.best_epoch = None # will be automatically assigned after 1 epoch\n",
    "        \n",
    "        if load_checkpoint: \n",
    "            assert load_optimizer is not None, 'load_checkpoint requires load_optimizer!'\n",
    "            self.optimizer = load_optimizer # load optimizer w/ state dict from checkpoint\n",
    "            \n",
    "            assert load_stats is not None, 'load_checkpoint requires load_stats!'\n",
    "            self.stats = load_stats\n",
    "            self.mean_train_loss = self.stats['mean_train_loss']\n",
    "            self.min_val_loss = self.stats['min_val_loss']\n",
    "            self.mean_val_loss = self.stats['mean_val_loss']\n",
    "            \n",
    "            assert begin_epoch is not None, 'load_checkpoint requires begin_epoch!'\n",
    "            self.begin_epoch = begin_epoch\n",
    "\n",
    "        else: # init fresh optimizer \n",
    "            self.optimizer = trainargs['optimizer'](model.parameters(), lr=trainargs['learning_rate'])\n",
    "            \n",
    "            self.mean_train_loss = []\n",
    "            self.min_val_loss = 1e9\n",
    "            self.mean_val_loss = []\n",
    "            self.begin_epoch = 1\n",
    "            self.stats = {'trainargs': self.trainargs, 'train_time': 0} # to store training statistics  \n",
    "\n",
    "        self.pin_memory = True if torch.cuda.is_available() else False\n",
    "        train_dataset = ReactionDataset(trainargs['base_path'], 'train', trainargs)\n",
    "        self.train_loader = DataLoader(train_dataset, trainargs['batch_size'], shuffle=True, pin_memory=self.pin_memory)\n",
    "        self.train_size = len(train_dataset)\n",
    "        \n",
    "        val_dataset = ReactionDataset(trainargs['base_path'], 'valid', trainargs)\n",
    "        self.val_loader = DataLoader(val_dataset, 2 * trainargs['batch_size'], shuffle=False, pin_memory=self.pin_memory)\n",
    "        self.val_size = len(val_dataset)\n",
    "        \n",
    "        test_dataset = ReactionDataset(self.trainargs['base_path'], 'test', self.trainargs)\n",
    "        self.test_loader = DataLoader(test_dataset, 2 * self.trainargs['batch_size'], shuffle=False, pin_memory=self.pin_memory)\n",
    "        self.test_size = len(test_dataset)\n",
    "        del train_dataset, val_dataset, test_dataset # save memory\n",
    "\n",
    "        torch.manual_seed(trainargs['model_seed'])\n",
    "        random.seed(trainargs['random_seed'])\n",
    "    \n",
    "    def train_one(self, batch, val=False):\n",
    "        '''\n",
    "        Trains model for 1 epoch\n",
    "        TO DO: learning rate scheduler + logger \n",
    "        '''\n",
    "        self.model.zero_grad()\n",
    "        scores = self.model(batch) # size N x K \n",
    "\n",
    "        softmax = nn.Softmax(dim=1) \n",
    "        probs = torch.clamp(softmax(scores), min=1e-12) # size N x K, clamped to >= 1e-12 for safe log \n",
    "\n",
    "        # positives are the 0-th index of each sample \n",
    "        loss = -torch.log(probs[:, 0]).sum() # probs[:, 0] is size N x 1 --> sum/mean to 1 value\n",
    "\n",
    "        if not val:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        '''\n",
    "        Trains model for epochs provided in trainargs\n",
    "        Currently supports feed-forward networks: \n",
    "            FF_diff: takes as input a difference FP of fp_size & fp_radius\n",
    "            FF_sep: takes as input a concatenation of [reactants FP, product FP] \n",
    "        '''\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in np.arange(self.begin_epoch, self.trainargs['epochs']): # epochs are 1-indexed (as of 27th Aug 2 am)\n",
    "            self.model.train() # set model to training mode\n",
    "            train_loss = []\n",
    "            for batch in tqdm(self.train_loader): \n",
    "                batch = batch.to(self.device)\n",
    "                train_loss.append(self.train_one(batch, val=False))\n",
    "            self.mean_train_loss.append(np.sum(train_loss) / self.train_size) \n",
    "\n",
    "            self.model.eval() # validation mode\n",
    "            val_loss = []\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(self.val_loader):\n",
    "                    batch = batch.to(self.device)\n",
    "                    val_loss.append(self.train_one(batch, val=True))\n",
    "                \n",
    "                self.mean_val_loss.append(np.sum(val_loss) / self.val_size)\n",
    "                if self.trainargs['early_stop'] and \\\n",
    "                self.min_val_loss - self.mean_val_loss[-1] < self.trainargs['min_delta']:\n",
    "                    if self.trainargs['patience'] <= wait:\n",
    "                        print('Early stopped at the end of epoch: ', epoch)\n",
    "                        print('mean_val_loss: ', self.mean_val_loss[-1])\n",
    "                        self.stats['early_stop_epoch'] = epoch \n",
    "                        break \n",
    "                    else:\n",
    "                        wait += 1\n",
    "                        print('Decrease in val loss < min_delta, patience count: ', wait)\n",
    "                else:\n",
    "                    wait = 0\n",
    "                    self.min_val_loss = min(self.min_val_loss, self.mean_val_loss[-1])\n",
    "                \n",
    "                if self.mean_val_loss[-1] < self.min_val_loss:\n",
    "                    self.best_epoch = epoch # track best_epoch to load best_checkpoint \n",
    "\n",
    "            self.stats['mean_train_loss'] = self.mean_train_loss\n",
    "            self.stats['mean_val_loss'] = self.mean_val_loss\n",
    "            self.stats['min_val_loss'] = self.min_val_loss\n",
    "            self.stats['best_epoch'] = self.best_epoch\n",
    "\n",
    "            if self.trainargs['checkpoint']: # adapted from moco: main_moco.py\n",
    "                save_checkpoint({\n",
    "                        'epoch': epoch, # epochs are 1-indexed\n",
    "                        'model': self.trainargs['model'],\n",
    "                        'state_dict': self.model.state_dict(),\n",
    "                        'optimizer' : self.optimizer.state_dict(),\n",
    "                        'stats' : self.stats,\n",
    "                    }, is_best=False, \n",
    "                    filename=self.trainargs['checkpoint_path']+'{}_{}_checkpoint_{:04d}.pth.tar'.format(\n",
    "                        self.trainargs['model'], self.trainargs['expt_name'], epoch))\n",
    "                # checkpoint stats also \n",
    "                torch.save(self.stats, self.trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(\n",
    "                      self.trainargs['model'], self.trainargs['expt_name']))\n",
    "                \n",
    "            print('Epoch: {}, train_loss: {}, val_loss: {}'.format(epoch, \n",
    "                                             np.around(self.mean_train_loss[-1], decimals=4), \n",
    "                                             np.around(self.mean_val_loss[-1], decimals=4)))\n",
    "            \n",
    "        self.stats['train_time'] += (time.time() - start) / 60\n",
    "        torch.save(self.stats, self.trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(\n",
    "            self.trainargs['model'], self.trainargs['expt_name']))         # save final training stats\n",
    "\n",
    "    def test(self, load_stats=None):\n",
    "        '''\n",
    "        Evaluates the model on the test set\n",
    "        '''\n",
    "        sum_test_loss, test_loss = [], []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.test_loader):\n",
    "                batch = batch.to(self.device)\n",
    "                sum_test_loss.append(self.train_one(batch, val=True))\n",
    "                test_loss.append(sum_test_loss[-1] / len(batch))\n",
    "        \n",
    "        if load_stats is not None: \n",
    "            self.stats = load_stats \n",
    "        assert len(self.stats.keys()) > 1, 'If loading checkpoint, you need to provide load_stats!'\n",
    "        \n",
    "        self.stats['test_loss'] = test_loss \n",
    "        self.stats['mean_test_loss'] = np.sum(sum_test_loss) / self.test_size\n",
    "        print('train_time: {}'.format(self.stats['train_time']))\n",
    "        print('test_loss: {}'.format(self.stats['test_loss']))\n",
    "        print('mean_test_loss: {}'.format(self.stats['mean_test_loss']))\n",
    "\n",
    "        # overrides existing training stats w/ training + test stats\n",
    "        torch.save(self.stats, self.trainargs['checkpoint_path']+'{}_{}_stats.pkl'.format(\n",
    "            self.trainargs['model'], self.trainargs['expt_name']))\n",
    "\n",
    "    def get_scores(self, dataloader, save_neg=False):\n",
    "        ''' \n",
    "        Gets raw energy values (scores) from a trained model on a given dataloader,\n",
    "        with the option to save pos_neg_smis to analyse model performance\n",
    "        \n",
    "        TO DO: fix save_neg: index into SMILES molecule vocab to retrieve molecules --> \n",
    "        save as groups [true product/rct SMILES, 1st NN SMILES, ... K-1'th NN SMILES])\n",
    "        '''\n",
    "        scores = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            if save_neg:      # save neg rxn_smis to analyse model performance           \n",
    "                pos_neg_smis = []\n",
    "                for pos_neg_smi, batch in tqdm(dataloader):\n",
    "                    batch = batch.to(self.device)\n",
    "                    scores.append(self.model(batch).cpu()) # scores: size N x K \n",
    "                    pos_neg_smis.append(pos_neg_smi)\n",
    "                torch.save(pos_neg_smis, self.trainargs['checkpoint_path']+'{}_{}_posnegsmi.pkl'.format(\n",
    "                        self.trainargs['model'], self.trainargs['expt_name']))\n",
    "                \n",
    "                return torch.cat(scores, dim=0), pos_neg_smis\n",
    "            else:\n",
    "                for batch in tqdm(dataloader):\n",
    "                    batch = batch.to(self.device)\n",
    "                    scores.append(self.model(batch).cpu())\n",
    "                \n",
    "                return torch.cat(scores, dim=0)\n",
    "\n",
    "    def get_topk_acc(self, dataloader, k=1, repeats=1, toprint=True):\n",
    "        '''\n",
    "        Computes top-k accuracy of trained model in classifying feasible vs infeasible chemical rxns\n",
    "        (i.e. maximum score assigned to label 0 of each training sample) \n",
    "        \n",
    "        Returns: (list of accs, mean acc, variance of acc)\n",
    "        '''\n",
    "        accs = np.array([])\n",
    "        for repeat in range(repeats):\n",
    "            scores = self.get_scores(dataloader)\n",
    "            predicted_labels = torch.topk(scores, k, dim=1)[1]\n",
    "            accs = np.append(accs, torch.where(predicted_labels == 0)[0].shape[0] / predicted_labels.shape[0])\n",
    "            \n",
    "        if toprint:\n",
    "            print('Top-1 accuracies: ', accs)\n",
    "            print('Avg top-1 accuracy: ', accs.mean())\n",
    "            print('Variance: ', accs.var())\n",
    "\n",
    "        return accs, accs.mean(), accs.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o12DGGe3ZZ2"
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPvEkk4hmbQ2"
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/tutorials/blob/master/beginner_source/data_loading_tutorial.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import pickle\n",
    "from scipy import sparse \n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def create_rxn_MorganFP_fromFP(raw_fp, num_rcts, fp_type='diff', \n",
    "                               rctfp_size=4096, prodfp_size=4096, dtype='int8'):\n",
    "    '''\n",
    "    fp_type: 'diff' or 'sep', \n",
    "    'diff' (difference):\n",
    "    Creates reaction MorganFP following Schneider et al in J. Chem. Inf. Model. 2015, 55, 1, 39–53\n",
    "    reactionFP = productFP - sum(reactantFPs)\n",
    "    \n",
    "    'sep' (separate):\n",
    "    Creates separate reactantsFP and productFP following Gao et al in ACS Cent. Sci. 2018, 4, 11, 1465–1476\n",
    "    '''\n",
    "    # initialise empty fp numpy arrays\n",
    "    if fp_type == 'diff':\n",
    "        diff_fp = np.zeros(rctfp_size, dtype = dtype)\n",
    "    elif fp_type == 'sep':\n",
    "        rcts_fp = np.zeros(rctfp_size, dtype = dtype)\n",
    "        prod_fp = np.zeros(prodfp_size, dtype = dtype)\n",
    "    else:\n",
    "        print('ERROR: fp_type not recognised!')\n",
    "        return\n",
    "    \n",
    "    # create product FP\n",
    "    try:\n",
    "        fp = raw_fp[-1]\n",
    "        if fp_type == 'diff':\n",
    "            diff_fp += fp\n",
    "        elif fp_type == 'sep':\n",
    "            prod_fp = fp\n",
    "    except Exception as e:\n",
    "        print(\"Cannot build product fp due to {}\".format(e))\n",
    "        return\n",
    "                                  \n",
    "    # create reactant FPs, subtracting each from product FP\n",
    "    for i in range(num_rcts):\n",
    "        try:\n",
    "            fp = raw_fp[i]\n",
    "            if fp_type == 'diff':\n",
    "                diff_fp -= fp\n",
    "            elif fp_type == 'sep':\n",
    "                rcts_fp += fp\n",
    "        except Exception as e:\n",
    "            print(\"Cannot build reactant fp due to {}\".format(e))\n",
    "            return\n",
    "    \n",
    "    if fp_type == 'diff':\n",
    "        return diff_fp\n",
    "    elif fp_type == 'sep':\n",
    "        return np.concatenate([rcts_fp, prod_fp])\n",
    "    \n",
    "    \n",
    "class ReactionDataset(Dataset):\n",
    "    '''\n",
    "    The Dataset class ReactionDataset prepares training samples of length K: \n",
    "    [pos_rxn, neg_rxn_1, ..., neg_rxn_K-1], ... where K-1 = num_neg \n",
    "\n",
    "    TO DO: can this be further optimised? Augmentation is the clear bottleneck during training\n",
    "    '''\n",
    "    def __init__(self, base_path, key, trainargs, \n",
    "                 show_neg=False, # for visualising nearest neighbors \n",
    "                 save_neg=False): # for rxn_smi (to fix later on)\n",
    "        '''\n",
    "        base_path is of the form: 'USPTO_50k_data/clean_rxn_50k_sparse_FPs', and according to key parameter,\n",
    "        the correct full path will be used e.g. 'USPTO_50k_data/clean_rxn_50k_sparse_FPs_train.npz'\n",
    "        ''' \n",
    "        self.fp_raw_num_rcts = sparse.load_npz(base_path + '_' + key + '.npz')\n",
    "        if 'cluster_path' in trainargs.keys(): # doing cosine similarity search\n",
    "            with open(trainargs['cluster_path'], 'rb') as handle:\n",
    "                self.clusterindex = pickle.load(handle)\n",
    "                \n",
    "            assert 'sparseFP_vocab_path' in trainargs.keys(), 'You provided cluster_path but not sparseFP_vocab_path!!'\n",
    "            self.sparseFP_vocab = sparse.load_npz(trainargs['sparseFP_vocab_path'])\n",
    "            \n",
    "            assert 'num_neg_prod' in trainargs.keys() and 'num_neg_rct' in trainargs.keys(), \\\n",
    "            'You provided cluster_path but not num_neg_prod and num_neg_rct!'\n",
    "            self.num_neg_prod = trainargs['num_neg_prod']\n",
    "            self.num_neg_rct = trainargs['num_neg_rct']\n",
    "        else:\n",
    "            assert 'num_neg' in trainargs.keys(), 'You did not provide num_neg!'\n",
    "            self.num_neg = trainargs['num_neg']\n",
    "        \n",
    "        self.fp_type = trainargs['fp_type']\n",
    "        \n",
    "        self.fp_radius = trainargs['fp_radius'] # not needed if loading pre-computed fingerprints\n",
    "        self.rctfp_size = trainargs['rctfp_size']\n",
    "        self.prodfp_size = trainargs['prodfp_size']\n",
    "        assert trainargs['rctfp_size'] == trainargs['prodfp_size']\n",
    "        self.save_neg = save_neg\n",
    "        self.show_neg = show_neg\n",
    "\n",
    "    def random_sample_negative(self, raw_fp, num_rcts):\n",
    "        '''\n",
    "        Randomly generates 1 negative rxn given a positive rxn fingerprint\n",
    "        Returns neg_rxn_fp (fingerprint)\n",
    "        ''' \n",
    "        rdm_rxn_idx = random.choice(np.arange(self.fp_raw_num_rcts.shape[0])) \n",
    "        new_fp_raw_num_rcts = self.fp_raw_num_rcts[rdm_rxn_idx].toarray()\n",
    "        new_raw_fp, _ = np.split(new_fp_raw_num_rcts, [new_fp_raw_num_rcts.shape[-1]-1], axis=1)\n",
    "        new_raw_fp = new_raw_fp.reshape(-1, self.rctfp_size)  \n",
    "        \n",
    "        rct_or_prod = random.choice([0, 1])\n",
    "        if rct_or_prod == 0: # randomly change one of the reactant(s)\n",
    "            rct_idx = random.choice(np.arange(num_rcts)) # randomly choose 1 reactant to be replaced\n",
    "            raw_fp[rct_idx, :] = new_raw_fp[rct_idx, :] \n",
    "        else:  # randomly change product \n",
    "            raw_fp[-1, :] = new_raw_fp[-1, :] \n",
    "        return raw_fp \n",
    "    \n",
    "    def cosine_sample_negative(self, raw_fp, num_rcts):\n",
    "        ''' \n",
    "        Replace product w/ approx nearest neighbor based on cosine similarity \n",
    "        \n",
    "        Args:\n",
    "            raw_fp: dense nparray fp of shape (max #rcts + 1, self.rctfp_size); for USPTO-50k, max #rcts = 4\n",
    "        \n",
    "        Returns:\n",
    "            list of num_neg X dense nparrays of the same shape as raw_fp, with product replaced \n",
    "        '''\n",
    "        rct_idx = random.choice(np.arange(num_rcts))\n",
    "        first_rct_prod_sparse = sparse.csr_matrix(raw_fp.copy()[[rct_idx, -1]], dtype='int8')\n",
    "        nn_rct_indices, nn_prod_indices = self.clusterindex.search(first_rct_prod_sparse, k=max(self.num_neg_prod, self.num_neg_rct)+1, \n",
    "                                                   return_distance=False)     #[0][1:]\n",
    "        nn_prod_indices, nn_rct_indices = [int(idx) for idx in nn_prod_indices], [int(idx) for idx in nn_rct_indices]\n",
    "        nn_prod_FPs = [self.sparseFP_vocab[idx].toarray() for idx in nn_prod_indices[1: self.num_neg_prod + 1]]\n",
    "        nn_rct_FPs = [self.sparseFP_vocab[idx].toarray() for idx in nn_rct_indices[1: self.num_neg_rct + 1]] # 1 x 4096 nparray\n",
    "\n",
    "        rct_FP_out = []\n",
    "        for rct_FP in nn_rct_FPs: # not sure how to do this via list comprehension to optimize it (lambda? but is it slower than for loop)\n",
    "          outputFP = raw_fp.copy()\n",
    "          outputFP[rct_idx] = rct_FP\n",
    "          rct_FP_out.append(outputFP)\n",
    "        \n",
    "        if self.show_neg:\n",
    "          return [np.vstack((raw_fp[:-1], FP)) for FP in nn_prod_FPs] + rct_FP_out, nn_prod_indices, nn_rct_indices\n",
    "        else:\n",
    "          return [np.vstack((raw_fp[:-1], FP)) for FP in nn_prod_FPs] + rct_FP_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ''' \n",
    "        Returns 1 training sample in the form [pos_rxn_fp, neg_rxn_1_fp, ..., neg_rxn_K-1_fp]\n",
    "        num_neg: a hyperparameter to be tuned\n",
    "        '''\n",
    "        if torch.is_tensor(idx): \n",
    "            idx = idx.tolist() \n",
    "\n",
    "        fp_raw_num_rcts = self.fp_raw_num_rcts[idx].toarray() \n",
    "        pos_raw_fp, num_rcts = np.split(fp_raw_num_rcts, [fp_raw_num_rcts.shape[-1]-1], axis=1) \n",
    "        pos_raw_fp = pos_raw_fp.reshape(-1, self.rctfp_size) \n",
    "        num_rcts = num_rcts[0][0]\n",
    "        pos_rxn_fp = create_rxn_MorganFP_fromFP(pos_raw_fp.copy(), num_rcts, fp_type=self.fp_type, \n",
    "                                                rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size)\n",
    "\n",
    "        assert self.num_neg_prod > 0 and self.num_neg_rct > 0, 'num_neg cannot be negative!'   \n",
    "        if 'cluster_path' in trainargs.keys(): # cosine similarity search\n",
    "          if self.show_neg:\n",
    "            neg_raw_fps, nn_prod_indices, nn_rct_indices = self.cosine_sample_negative(pos_raw_fp, num_rcts)\n",
    "          else:\n",
    "            neg_raw_fps = self.cosine_sample_negative(pos_raw_fp, num_rcts)\n",
    "        else:\n",
    "            neg_raw_fps = [self.random_sample_negative(pos_raw_fp.copy(), num_rcts) for i in range(self.num_neg)]\n",
    "        neg_rxn_fps = [create_rxn_MorganFP_fromFP(neg_raw_fp.copy(), num_rcts, fp_type=self.fp_type, \n",
    "                                                  rctfp_size=self.rctfp_size, prodfp_size=self.prodfp_size)\n",
    "                        for neg_raw_fp in neg_raw_fps]\n",
    "        if self.show_neg:\n",
    "          return torch.Tensor([pos_rxn_fp, *neg_rxn_fps]), nn_prod_indices, nn_rct_indices\n",
    "        else:\n",
    "          return torch.Tensor([pos_rxn_fp, *neg_rxn_fps])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.fp_raw_num_rcts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_g3HfHMOHcN5"
   },
   "outputs": [],
   "source": [
    "test_dataset_showneg = ReactionDataset(stats['trainargs']['base_path'], 'test', stats['trainargs'], show_neg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRKEv9n8I2ts"
   },
   "outputs": [],
   "source": [
    "with open('/content/gdrive/My Drive/rxn_ebm/USPTO_50k_Schneider/50k_unique_rcts_prod_smis.pickle', 'rb') as handle:\n",
    "    unique_mols_50k = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bxIpKFZXLyJv",
    "outputId": "d9dece98-2c43-423b-d222-1fd04b85ae5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ -4.0585,  -4.0585, -17.4343, -12.1690,  -8.2925]), 987)"
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "too_similar_idx = torch.where(scores[:, 0] == scores[:, 1])\n",
    "scores[too_similar_idx[0][986]], len(too_similar_idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0_7M53V6OJaK",
    "outputId": "5cafe96d-85ba-4f78-8b01-90b05192c9aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(False), tensor(False), tensor(False))"
      ]
     },
     "execution_count": 168,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_fps = test_dataset_showneg.__getitem__(too_similar_idx[0][986])[0]\n",
    "torch.all(diff_fps[0] == diff_fps[1]), torch.all(diff_fps[0] == diff_fps[2]), torch.all(diff_fps[0] == diff_fps[3]), torch.all(diff_fps[0] == diff_fps[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "-5uZdfM4Kr51",
    "outputId": "3b4550e8-5c49-4fb5-c998-0ff72b0c8cbb"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"200px\" version=\"1.1\" viewBox=\"0 0 900 200\" width=\"900px\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<!-- END OF HEADER -->\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<path class=\"bond-0\" d=\"M 119.785,48.4211 L 119.747,67.1216\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0\" d=\"M 123.525,48.4288 L 123.487,67.1292\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 121.617,67.1254 L 105.403,76.4425\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 105.403,76.4425 L 105.365,95.1429\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 105.365,95.1429 L 121.54,104.526\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 105.914,99.7856 L 117.237,106.354\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-33\" d=\"M 105.365,95.1429 L 89.1504,104.46\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 121.54,104.526 L 128.192,100.704\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 128.192,100.704 L 134.844,96.8818\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 121.54,104.526 L 121.502,123.227\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 140.666,96.8977 L 147.298,100.745\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 147.298,100.745 L 153.931,104.592\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 153.931,104.592 L 170.145,95.2753\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 170.145,95.2753 L 186.321,104.659\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 186.321,104.659 L 192.972,100.836\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 192.972,100.836 L 199.624,97.0142\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 205.446,97.03 L 212.078,100.877\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 212.078,100.877 L 218.711,104.725\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 218.711,104.725 L 218.673,123.425\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 222.445,107.537 L 222.418,120.628\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-34\" d=\"M 218.711,104.725 L 234.925,95.4076\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 218.673,123.425 L 234.848,132.808\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 234.848,132.808 L 251.063,123.491\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 235.417,128.168 L 246.767,121.646\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 251.063,123.491 L 267.239,132.875\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 251.063,123.491 L 251.101,104.791\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14\" d=\"M 267.239,132.875 L 267.2,151.575\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 268.17,134.496 L 274.822,130.674\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 274.822,130.674 L 281.473,126.852\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 266.307,131.253 L 272.958,127.431\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 272.958,127.431 L 279.61,123.609\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 251.101,104.791 L 257.752,100.969\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 257.752,100.969 L 264.404,97.1465\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 251.101,104.791 L 234.925,95.4076\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 246.798,106.619 L 235.475,100.05\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 234.925,95.4076 L 234.963,76.7072\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20\" d=\"M 234.963,76.7072 L 251.177,67.3901\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21\" d=\"M 251.177,67.3901 L 251.215,48.6896\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-23\" d=\"M 121.502,123.227 L 105.288,132.544\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-23\" d=\"M 117.207,121.381 L 105.857,127.903\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-24\" d=\"M 105.288,132.544 L 89.1122,123.16\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-25\" d=\"M 89.1122,123.16 L 81.6692,125.562\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-25\" d=\"M 81.6692,125.562 L 74.2262,127.964\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-35\" d=\"M 89.1122,123.16 L 89.1504,104.46\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-35\" d=\"M 92.858,120.363 L 92.8848,107.273\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 69.0605,125.786 L 64.7074,119.769\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 64.7074,119.769 L 60.3543,113.751\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-27\" d=\"M 60.3543,113.751 L 41.6539,113.713\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-31\" d=\"M 60.3543,113.751 L 71.3771,98.645\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-31\" d=\"M 65.029,113.69 L 72.745,103.115\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 40.0363,112.775 L 36.2486,119.305\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 36.2486,119.305 L 32.461,125.834\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 43.2715,114.652 L 39.4838,121.181\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 39.4838,121.181 L 35.6962,127.711\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-29\" d=\"M 41.6539,113.713 L 37.8908,107.165\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-29\" d=\"M 37.8908,107.165 L 34.1278,100.616\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-30\" d=\"M 29.4258,97.4932 L 21.5311,97.477\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-30\" d=\"M 21.5311,97.477 L 13.6364,97.4609\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-32\" d=\"M 71.3771,98.645 L 89.1504,104.46\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"middle\" x=\"137.755\" y=\"96.1441\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"middle\" x=\"202.535\" y=\"96.2765\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"281.165\" y=\"124.493\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"265.027\" y=\"96.4088\"><tspan>OH</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"middle\" x=\"71.3153\" y=\"129.838\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"end\" x=\"34.5582\" y=\"130.824\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"30.0492\" y=\"98.4341\"><tspan>O</tspan></text>\n",
       "<path class=\"bond-0\" d=\"M 383.392,132.959 L 386.929,126.245\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0\" d=\"M 386.929,126.245 L 390.466,119.531\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 394.81,116.31 L 402.802,116\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 402.802,116 L 410.795,115.691\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 409.213,116.688 L 413.216,123.04\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 413.216,123.04 L 417.218,129.393\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 412.377,114.694 L 416.38,121.046\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 416.38,121.046 L 420.383,127.399\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 410.795,115.691 L 419.512,99.1464\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 419.512,99.1464 L 409.542,83.3251\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 421.181,94.7793 L 414.202,83.7044\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20\" d=\"M 419.512,99.1464 L 438.198,98.4232\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 409.542,83.3251 L 418.259,66.7805\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 418.259,66.7805 L 436.945,66.0572\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 421.207,70.4093 L 434.287,69.903\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 436.945,66.0572 L 446.915,81.8786\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 446.915,81.8786 L 438.198,98.4232\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 442.299,82.6169 L 436.197,94.1981\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 438.198,98.4232 L 442.201,104.775\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 442.201,104.775 L 446.204,111.128\" style=\"fill:none;fill-rule:evenodd;stroke:#CCCC00;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 450.663,114.148 L 458.759,113.835\" style=\"fill:none;fill-rule:evenodd;stroke:#CCCC00;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 458.759,113.835 L 466.854,113.521\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 466.854,113.521 L 476.824,129.342\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 471.514,113.9 L 478.493,124.975\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21\" d=\"M 466.854,113.521 L 475.571,96.9766\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 476.824,129.342 L 495.51,128.619\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 495.51,128.619 L 504.227,112.075\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 493.509,124.394 L 499.611,112.813\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14\" d=\"M 504.227,112.075 L 522.355,107.482\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 504.227,112.075 L 494.258,96.2533\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 522.355,107.482 L 529.02,113.032\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 529.02,113.032 L 535.686,118.582\" style=\"fill:none;fill-rule:evenodd;stroke:#A01EEF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 522.355,107.482 L 522.869,99.7105\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 522.869,99.7105 L 523.383,91.9391\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 518.777,104.904 L 519.137,99.4637\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 519.137,99.4637 L 519.497,94.0237\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 520.887,87.7427 L 508.925,82.9622\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 503.629,84.9993 L 498.943,90.6263\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 498.943,90.6263 L 494.258,96.2533\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 494.258,96.2533 L 475.571,96.9766\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 491.599,100.099 L 478.519,100.605\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"end\" x=\"394.186\" y=\"117.349\"><tspan>HN</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"418.477\" y=\"132.447\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#CCCC00\" text-anchor=\"end\" x=\"450.04\" y=\"115.179\"><tspan>S</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#A01EEF\" text-anchor=\"start\" x=\"536.309\" y=\"120.383\"><tspan>I</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"521.511\" y=\"89.7573\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"middle\" x=\"506.224\" y=\"82.8176\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"504.146\" y=\"76.5841\"><tspan>H</tspan></text>\n",
       "<path class=\"bond-0\" d=\"M 724.185,69.0101 L 716.636,86.119\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 716.636,86.119 L 727.678,101.211\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 716.636,86.119 L 698.045,88.1356\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 725.967,100.456 L 722.88,107.453\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 722.88,107.453 L 719.793,114.449\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 729.389,101.966 L 726.302,108.962\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 726.302,108.962 L 723.215,115.958\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 727.678,101.211 L 735.623,100.35\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 735.623,100.35 L 743.568,99.4877\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 748.55,102.311 L 752.931,108.299\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 752.931,108.299 L 757.312,114.287\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 757.312,114.287 L 775.903,112.27\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 775.903,112.27 L 786.945,127.363\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 780.578,112.326 L 788.307,122.89\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-29\" d=\"M 775.903,112.27 L 783.452,95.1615\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 786.945,127.363 L 805.537,125.346\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 805.537,125.346 L 813.086,108.237\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 803.247,121.27 L 808.532,109.294\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 813.086,108.237 L 821.031,107.375\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 821.031,107.375 L 828.976,106.514\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 813.086,108.237 L 802.044,93.1449\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 832.783,103.104 L 835.355,95.8496\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 835.355,95.8496 L 837.927,88.5953\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-31\" d=\"M 833.618,109.337 L 837.589,115.717\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-31\" d=\"M 837.589,115.717 L 841.561,122.096\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 837.927,88.5953 L 855.604,82.4923\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 855.604,82.4923 L 871.396,92.5072\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 871.396,92.5072 L 873.413,111.099\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14\" d=\"M 873.413,111.099 L 860.135,124.267\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 860.135,124.267 L 841.561,122.096\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 802.044,93.1449 L 805.131,86.1488\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 805.131,86.1488 L 808.218,79.1527\" style=\"fill:none;fill-rule:evenodd;stroke:#33CCCC;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 802.044,93.1449 L 783.452,95.1615\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 799.658,97.1656 L 786.644,98.5773\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20\" d=\"M 698.045,88.1356 L 687.003,73.0433\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20\" d=\"M 693.37,88.0802 L 685.64,77.5156\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-30\" d=\"M 698.045,88.1356 L 690.495,105.245\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21\" d=\"M 687.003,73.0433 L 668.411,75.0599\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 668.411,75.0599 L 660.862,92.1688\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 670.701,79.1361 L 665.416,91.1124\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-23\" d=\"M 660.862,92.1688 L 671.904,107.261\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-24\" d=\"M 671.904,107.261 L 664.355,124.37\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-24\" d=\"M 674.193,111.337 L 668.909,123.314\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-32\" d=\"M 671.904,107.261 L 690.495,105.245\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-25\" d=\"M 664.355,124.37 L 668.736,130.358\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-25\" d=\"M 668.736,130.358 L 673.117,136.346\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 678.098,139.169 L 686.043,138.308\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 686.043,138.308 L 693.988,137.446\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 680.078,135.193 L 685.64,134.589\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 685.64,134.589 L 691.201,133.986\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-27\" d=\"M 693.988,137.446 L 701.538,120.337\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 701.538,120.337 L 690.495,105.245\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 696.863,120.281 L 689.133,109.717\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"end\" x=\"722.417\" y=\"119.255\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"744.192\" y=\"100.13\"><tspan>NH</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"829.599\" y=\"107.156\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#33CCCC\" text-anchor=\"start\" x=\"807.93\" y=\"76.971\"><tspan>F</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"end\" x=\"677.475\" y=\"140.397\"><tspan>N</tspan></text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_prod_indices = test_dataset_showneg.__getitem__(too_similar_idx[0][986])[1]\n",
    "result_mols = [Chem.MolFromSmiles(unique_mols_50k[idx]) for idx in nn_prod_indices]\n",
    "Draw.MolsToGridImage(result_mols, subImgSize=(300, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "l5mN1EIYK9d8",
    "outputId": "3bd08827-8304-4516-8269-3e78b32369a1"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"200px\" version=\"1.1\" viewBox=\"0 0 900 200\" width=\"900px\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<!-- END OF HEADER -->\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"900\" x=\"0\" y=\"0\"> </rect>\n",
       "<path class=\"bond-0\" d=\"M 39.2426,54.2262 L 45.7937,60.7872\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0\" d=\"M 45.7937,60.7872 L 52.3447,67.3483\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 54.9815,75.0199 L 52.4277,84.5218\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 52.4277,84.5218 L 49.8739,94.0238\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 49.2601,91.7261 L 39.6225,94.3006\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 39.6225,94.3006 L 29.985,96.8751\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 50.4877,96.3216 L 40.8501,98.8961\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 40.8501,98.8961 L 31.2126,101.471\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 49.8739,94.0238 L 66.6781,110.854\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 66.6781,110.854 L 65.1244,120.615\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 65.1244,120.615 L 63.5706,130.377\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-30\" d=\"M 66.6781,110.854 L 90.171,107.151\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-30\" d=\"M 70.9425,114.997 L 87.3876,112.405\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 66.3754,136.095 L 75.2488,140.624\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 75.2488,140.624 L 84.1222,145.154\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 71.2001,133.217 L 77.4115,136.388\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 77.4115,136.388 L 83.6229,139.559\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 84.1222,145.154 L 90.8193,138.467\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 90.8193,138.467 L 97.5164,131.78\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 104.388,128.897 L 114.413,130.493\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 114.413,130.493 L 124.439,132.088\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-23\" d=\"M 98.9362,124.386 L 94.5536,115.769\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-23\" d=\"M 94.5536,115.769 L 90.171,107.151\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 124.439,132.088 L 132.945,154.298\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-32\" d=\"M 124.439,132.088 L 139.42,113.617\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 132.945,154.298 L 156.433,158.036\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 156.433,158.036 L 171.414,139.565\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 171.414,139.565 L 167.92,130.442\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 167.92,130.442 L 164.426,121.319\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 166.122,113.392 L 172.006,106.138\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 172.006,106.138 L 177.889,98.884\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 159.472,116.809 L 149.446,115.213\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 149.446,115.213 L 139.42,113.617\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 180.11,98.0334 L 176.616,88.9104\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 176.616,88.9104 L 173.122,79.7875\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 175.668,99.7346 L 172.174,90.6117\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 172.174,90.6117 L 168.68,81.4887\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14\" d=\"M 177.889,98.884 L 187.781,100.459\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14\" d=\"M 187.781,100.459 L 197.674,102.033\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 204.591,98.6585 L 210.474,91.4048\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 210.474,91.4048 L 216.357,84.151\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 216.357,84.151 L 239.844,87.8894\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 239.844,87.8894 L 248.35,110.099\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 245.562,89.5196 L 251.516,105.066\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-33\" d=\"M 239.844,87.8894 L 254.825,69.418\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 248.35,110.099 L 271.838,113.837\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 271.838,113.837 L 286.819,95.3661\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 270.391,108.07 L 280.877,95.1405\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20\" d=\"M 286.819,95.3661 L 278.313,73.1563\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21\" d=\"M 278.313,73.1563 L 254.825,69.418\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21\" d=\"M 274.042,77.293 L 257.601,74.6762\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-24\" d=\"M 90.171,107.151 L 100.984,85.9686\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-25\" d=\"M 100.984,85.9686 L 124.736,84.742\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-25\" d=\"M 104.302,81.0344 L 120.928,80.1758\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-31\" d=\"M 100.984,85.9686 L 88.0464,66.0128\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-26\" d=\"M 124.736,84.742 L 135.549,63.5596\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-27\" d=\"M 135.549,63.5596 L 122.611,43.6037\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-27\" d=\"M 129.617,63.1538 L 120.561,49.1847\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-28\" d=\"M 122.611,43.6037 L 98.8598,44.8303\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-29\" d=\"M 98.8598,44.8303 L 88.0464,66.0128\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-29\" d=\"M 101.474,50.1704 L 93.9049,64.9981\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"53.1375\" y=\"72.2452\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"end\" x=\"29.806\" y=\"101.351\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"end\" x=\"65.5826\" y=\"135.53\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"98.3092\" y=\"129.539\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"middle\" x=\"162.908\" y=\"118.545\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"end\" x=\"172.292\" y=\"77.8634\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"198.467\" y=\"103.812\"><tspan>O</tspan></text>\n",
       "<path class=\"bond-0\" d=\"M 373.817,104.419 L 382.527,99.9109\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0\" d=\"M 382.527,99.9109 L 391.237,95.403\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 398.641,95.8577 L 406.804,101.085\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 406.804,101.085 L 414.967,106.313\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 412.591,106.203 L 412.136,116.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 412.136,116.1 L 411.68,125.997\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 417.343,106.422 L 416.887,116.319\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 416.887,116.319 L 416.432,126.216\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 414.967,106.313 L 436.088,95.3807\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 436.088,95.3807 L 437.182,71.623\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 441.004,92.0357 L 441.769,75.4053\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 436.088,95.3807 L 456.117,108.206\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 437.182,71.623 L 458.303,60.691\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 458.303,60.691 L 478.331,73.5167\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 458.742,66.6205 L 472.762,75.5985\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 478.331,73.5167 L 477.238,97.2745\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 477.238,97.2745 L 497.266,110.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 477.238,97.2745 L 456.117,108.206\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 471.883,94.69 L 457.098,102.342\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 494.89,109.991 L 494.435,119.888\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 494.435,119.888 L 493.979,129.785\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 499.642,110.21 L 499.186,120.107\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 499.186,120.107 L 498.731,130.003\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"middle\" x=\"394.939\" y=\"94.676\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"410.964\" y=\"131.26\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"493.263\" y=\"135.047\"><tspan>O</tspan></text>\n",
       "<path class=\"bond-0\" d=\"M 613.007,100.463 L 633.213,113.006\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 633.213,113.006 L 641.845,108.383\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1\" d=\"M 641.845,108.383 L 650.477,103.76\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 657.881,104.075 L 666.133,109.197\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2\" d=\"M 666.133,109.197 L 674.386,114.32\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 672.008,114.244 L 671.692,124.147\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 671.692,124.147 L 671.376,134.051\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 676.763,114.395 L 676.447,124.299\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3\" d=\"M 676.447,124.299 L 676.131,134.202\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4\" d=\"M 674.386,114.32 L 695.351,103.091\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 695.351,103.091 L 715.558,115.633\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5\" d=\"M 695.873,109.014 L 710.018,117.793\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6\" d=\"M 715.558,115.633 L 736.523,104.405\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 736.523,104.405 L 757.93,114.766\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7\" d=\"M 741.806,101.678 L 756.791,108.931\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21\" d=\"M 736.523,104.405 L 739.762,80.8437\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 757.93,114.766 L 764.447,107.977\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8\" d=\"M 764.447,107.977 L 770.964,101.188\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 777.835,98.0811 L 787.898,99.4645\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9\" d=\"M 787.898,99.4645 L 797.961,100.848\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16\" d=\"M 772.277,93.645 L 765.294,80.6072\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 797.961,100.848 L 806.936,122.872\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10\" d=\"M 803.712,102.356 L 809.995,117.773\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 797.961,100.848 L 803.715,93.4373\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-22\" d=\"M 803.715,93.4373 L 809.469,86.0266\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11\" d=\"M 806.936,122.872 L 830.498,126.111\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 830.498,126.111 L 845.084,107.326\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12\" d=\"M 828.929,120.376 L 839.139,107.227\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 845.084,107.326 L 854.618,108.637\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13\" d=\"M 854.618,108.637 L 864.153,109.948\" style=\"fill:none;fill-rule:evenodd;stroke:#00CC00;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14\" d=\"M 845.084,107.326 L 836.108,85.3019\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 836.108,85.3019 L 826.045,83.9185\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 826.045,83.9185 L 815.982,82.5351\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 832.441,89.5992 L 825.397,88.6308\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15\" d=\"M 825.397,88.6308 L 818.353,87.6624\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 759.736,77.2599 L 749.749,79.0518\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 749.749,79.0518 L 739.762,80.8437\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 757.58,82.4793 L 750.589,83.7336\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17\" d=\"M 750.589,83.7336 L 743.598,84.9879\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18\" d=\"M 739.762,80.8437 L 722.605,64.3742\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19\" d=\"M 722.605,64.3742 L 728.289,41.2806\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20\" d=\"M 722.605,64.3742 L 699.763,70.9984\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"middle\" x=\"654.179\" y=\"102.966\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#FF0000\" text-anchor=\"start\" x=\"670.718\" y=\"139.279\"><tspan>O</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"771.757\" y=\"98.7979\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#00CC00\" text-anchor=\"start\" x=\"864.946\" y=\"111.754\"><tspan>Cl</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"end\" x=\"815.19\" y=\"83.252\"><tspan>N</tspan></text>\n",
       "<text dominant-baseline=\"central\" style=\"font-size:7px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;fill:#0000FF\" text-anchor=\"start\" x=\"760.528\" y=\"77.8326\"><tspan>N</tspan></text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_rct_indices = test_dataset_showneg.__getitem__(too_similar_idx[0][986])[2]\n",
    "result_mols = [Chem.MolFromSmiles(unique_mols_50k[idx]) for idx in nn_rct_indices]\n",
    "Draw.MolsToGridImage(result_mols, subImgSize=(300, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ti5ndWB3ZaA"
   },
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "890bgQ783ZaB"
   },
   "outputs": [],
   "source": [
    "trainargs = {\n",
    "    'model': 'FF_diff', # must change both model & fp_type \n",
    "    'hidden_sizes': [384],  \n",
    "    'output_size': 1,\n",
    "    'dropout': 0.2,  \n",
    "    \n",
    "    'batch_size': 64,\n",
    "    'activation': 'ReLU',  \n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 5e-3, # to try: lr_finder & lr_schedulers \n",
    "    'epochs': 50,\n",
    "    'early_stop': True,\n",
    "    'min_delta': 1e-4, # we just want to watch out for when val_loss increases\n",
    "    'patience': 2,\n",
    "\n",
    "    'checkpoint': True,\n",
    "    'model_seed': 1337,\n",
    "    'random_seed': 0, # affects neg rxn sampling since it is random\n",
    "    \n",
    "    'rctfp_size': 4096, # if fp_type == 'diff', ensure that both rctfp_size & prodfp_size are identical!\n",
    "    'prodfp_size': 4096,\n",
    "    'fp_radius': 3,\n",
    "    'fp_type': 'diff',\n",
    "    \n",
    "    'num_neg_prod': 5,\n",
    "    'num_neg_rct': 5,\n",
    "    \n",
    "    'base_path': base_path, # refer to top of notebook \n",
    "    'checkpoint_path': checkpoint_folder,\n",
    "    'cluster_path': cluster_path,\n",
    "    'sparseFP_vocab_path': sparseFP_vocab_path,\n",
    " \n",
    "    'expt_name': 'MONO_cosine_4096_1layer384_PERMUTE5prod5rct_rad3_ReLU_drop2',\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mlGGCOZBEz4"
   },
   "outputs": [],
   "source": [
    "model = FF_ebm(trainargs)\n",
    "run = Run(model, trainargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4VxMcBNmbRF"
   },
   "source": [
    "### options to speed up:\n",
    "- precompute nearest neighbors (i.e. only need to calculate once, store as sparseFPs)\n",
    "- ~use separate num_rcts list~ \n",
    "- ~use mono ClusterIndex (~2x faster) but sacrifice some recall~\n",
    "- is np.vstack slow? \n",
    "- lower num_neg but may sacrifice model performance\n",
    "- think about how to design a collate_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "oAQVPmtNBAuo",
    "outputId": "8a299bdb-ca06-45b9-be7b-495e5d3d1921"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:10<00:00,  1.28it/s]\n",
      "100%|██████████| 40/40 [01:00<00:00,  1.51s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss: 0.9462, val_loss: 0.4481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:55<00:00,  1.32it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.48s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train_loss: 0.5276, val_loss: 0.3477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:03<00:00,  1.29it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.48s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, train_loss: 0.4079, val_loss: 0.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:04<00:00,  1.29it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.48s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train_loss: 0.347, val_loss: 0.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:08<00:00,  1.28it/s]\n",
      "100%|██████████| 40/40 [01:00<00:00,  1.51s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train_loss: 0.3086, val_loss: 0.2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:58<00:00,  1.31it/s]\n",
      "100%|██████████| 40/40 [00:57<00:00,  1.45s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train_loss: 0.2797, val_loss: 0.2769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:02<00:00,  1.30it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.50s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, train_loss: 0.2609, val_loss: 0.2724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:58<00:00,  1.31it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.48s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrease in val loss < min_delta, patience count:  1\n",
      "Epoch: 8, train_loss: 0.2446, val_loss: 0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:12<00:00,  1.27it/s]\n",
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, train_loss: 0.2267, val_loss: 0.2705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:51<00:00,  1.33it/s]\n",
      "100%|██████████| 40/40 [00:58<00:00,  1.46s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train_loss: 0.2169, val_loss: 0.2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:56<00:00,  1.31it/s]\n",
      "100%|██████████| 40/40 [00:58<00:00,  1.46s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, train_loss: 0.211, val_loss: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:08<00:00,  1.28it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.49s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, train_loss: 0.1963, val_loss: 0.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [08:04<00:00,  1.29it/s]\n",
      "100%|██████████| 40/40 [00:59<00:00,  1.50s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrease in val loss < min_delta, patience count:  1\n",
      "Epoch: 13, train_loss: 0.1919, val_loss: 0.2655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:43<00:00,  1.35it/s]\n",
      "100%|██████████| 40/40 [00:57<00:00,  1.43s/it]\n",
      "  0%|          | 0/626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrease in val loss < min_delta, patience count:  2\n",
      "Epoch: 14, train_loss: 0.187, val_loss: 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626/626 [07:53<00:00,  1.32it/s]\n",
      "100%|██████████| 40/40 [00:58<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at the end of epoch:  15\n",
      "mean_val_loss:  0.2712373028896113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bfmFtR4qBjrf",
    "outputId": "8474191d-7311-4742-e658-c2cc063219c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:57<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_time: 134.98899006843567\n",
      "test_loss: [0.34486013650894165, 0.21350349485874176, 0.316318541765213, 0.3600781559944153, 0.3259674608707428, 0.30812811851501465, 0.3269449472427368, 0.19993144273757935, 0.3359689712524414, 0.300240159034729, 0.257930725812912, 0.278262197971344, 0.24062779545783997, 0.33006447553634644, 0.4392233192920685, 0.48624366521835327, 0.3170953691005707, 0.3175897002220154, 0.1483258455991745, 0.2761147618293762, 0.18926283717155457, 0.33126699924468994, 0.303907573223114, 0.19922403991222382, 0.28010982275009155, 0.17266088724136353, 0.19850485026836395, 0.18065138161182404, 0.3039328455924988, 0.30969226360321045, 0.18357282876968384, 0.27592340111732483, 0.24500435590744019, 0.17461293935775757, 0.26065805554389954, 0.39882993698120117, 0.23924529552459717, 0.26926708221435547, 0.15476784110069275, 0.11207989056905111]\n",
      "mean_test_loss: 0.2762890068242382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Z0Al-u10mbRM",
    "outputId": "a484598e-5178-44e9-ca07-4771093ef846"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:56<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracies:  [0.91471939]\n",
      "Avg top-1 accuracy:  0.91471939285001\n",
      "Variance:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.91471939]), 0.91471939285001, 0.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = ReactionDataset(trainargs['base_path'], 'test', trainargs)\n",
    "test_loader = DataLoader(test_dataset, 2 * trainargs['batch_size'], shuffle=False)\n",
    "\n",
    "run.get_topk_acc(test_loader, 1, repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q-vo_eJCmbRR",
    "outputId": "13a00aa3-a7e4-4a78-b672-0bed7f318334"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:58<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "scores = run.get_scores(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "-4AfQANpmbRU",
    "outputId": "bb8539cf-a03a-4880-ecf0-462b7f6d7136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.3080, -27.3587, -28.1888, -28.0778, -26.1979, -32.6639, -18.0499,\n",
       "         -21.9614, -20.7868, -22.0446, -23.1673],\n",
       "        [-18.4102, -49.4610, -45.9350, -50.6376, -47.8758, -49.2555, -20.8611,\n",
       "         -21.2184, -29.7202, -29.4258, -28.7391],\n",
       "        [ -9.1878, -19.4630, -21.0764, -42.5246, -44.0958, -44.7666, -26.7794,\n",
       "         -23.3455, -30.4753, -27.2496, -32.9655],\n",
       "        [-12.3116, -23.4847, -26.6976, -37.9741, -39.0944, -41.2545, -20.6920,\n",
       "         -23.0860, -22.7468, -22.0501, -21.4243],\n",
       "        [ -8.7711, -18.8178, -38.3750, -26.8047, -36.3992, -37.1154, -23.0179,\n",
       "         -24.7012, -24.3654, -25.1083, -28.7611],\n",
       "        [-11.8389, -26.9684, -25.5917, -22.5330, -22.2901, -20.2715, -28.5865,\n",
       "         -24.0738, -30.3429, -29.0659, -31.0904],\n",
       "        [-16.0913, -24.5893, -36.2138, -42.3736, -38.9018, -44.0648, -24.5893,\n",
       "         -35.1414, -30.9030, -30.5106, -29.9173],\n",
       "        [-10.9674, -12.3991, -13.2561, -23.1595, -20.1408, -25.0833, -20.0677,\n",
       "         -22.8411, -19.1032, -22.5713, -21.5024],\n",
       "        [ -6.6151, -14.2731, -15.5869, -19.7329, -24.9799, -19.5978, -28.3492,\n",
       "         -24.6697, -29.6575, -30.0979, -29.8648],\n",
       "        [-16.9440, -22.2017, -15.0723, -18.9270, -44.7135, -52.5898, -22.5491,\n",
       "         -19.7828, -18.9270, -32.8487, -16.4786],\n",
       "        [-19.6033, -18.9270, -39.0992, -40.2622, -33.9368, -45.9668, -18.9270,\n",
       "         -38.6170, -35.1520, -47.7574, -37.8518],\n",
       "        [-14.4343, -29.9439, -22.8957, -25.1208, -22.5321, -14.7434, -20.1728,\n",
       "         -22.2450, -20.5352, -19.9023, -21.2264],\n",
       "        [-13.6199, -21.0486, -18.9270, -31.3709, -47.0197, -45.5935, -18.9270,\n",
       "         -20.5384, -26.1519, -41.9675, -39.4811],\n",
       "        [-16.9666, -21.6718, -26.3063, -29.6978, -33.3406, -29.9352, -28.2854,\n",
       "         -34.1386, -31.6649, -34.3623, -32.0684],\n",
       "        [-12.2784, -17.4466, -23.9386, -21.5823, -21.4127, -28.0340, -18.8269,\n",
       "         -20.6489, -17.2705, -21.0278, -19.5071],\n",
       "        [-15.7392, -36.1993, -45.9054, -38.5132, -56.4876, -56.0888, -32.0130,\n",
       "         -34.6144, -29.5309, -27.1651, -32.3540],\n",
       "        [-13.6273, -19.5078, -21.2644, -22.0131, -21.7774, -41.3836, -19.3554,\n",
       "         -19.1996, -30.4965, -23.2785, -19.7010],\n",
       "        [-18.1696, -21.6751, -38.0551, -72.3188, -70.2691, -77.1792, -26.8507,\n",
       "         -25.8114, -30.1170, -72.3188, -30.6076],\n",
       "        [ -9.1021, -23.1618, -25.3824, -26.9719, -25.7876, -31.0739, -16.4473,\n",
       "         -20.3693, -21.4152, -19.2327, -20.4722],\n",
       "        [-16.5197, -53.3587, -71.1106, -63.4855, -58.2079, -57.3388, -23.0163,\n",
       "         -24.9681, -24.1355, -24.9249, -34.7719]])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QsdBaiyRRL-v",
    "outputId": "92ace800-d891-4a91-bbf3-060d09601201"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(scores[:, 0] == scores[:, 1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "l9sXQdKPUk5C",
    "outputId": "9d50b6b3-052e-4bbb-ff13-fcff652c0dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of test samples w/ same score assigned to pos_rxn & nearest prod: 0.07989\n",
      "% of test samples w/ same score assigned to pos_rxn & 2nd nearest prod: 0.00000\n",
      "% of test samples w/ same score assigned to pos_rxn & nearest rct: 0.00000\n",
      "% of test samples w/ same score assigned to pos_rxn & 2nd nearest rct: 0.00000\n",
      "% of test samples w/ same score assigned to pos_rxn & nearest rct & prod (in same sample): 0.00000\n"
     ]
    }
   ],
   "source": [
    "print('% of test samples w/ same score assigned to pos_rxn & nearest prod: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 1])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & 2nd nearest prod: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 2])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & nearest rct: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 4])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & 2nd nearest rct: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 5])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & nearest rct & prod (in same sample): {:.5f}'.format( \n",
    "      len(torch.where((scores[:, 0] == scores[:, 4]) & (scores[:, 0] == scores[:, 1]))[0]) / len(test_dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qffy5xFE-pze"
   },
   "outputs": [],
   "source": [
    "torch.save(scores, '/content/gdrive/My Drive/rxn_ebm/scores_sepnumneg_fixed_MONO_PERMUTE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0R5fkcaEBkV5",
    "outputId": "84fb61db-5b45-4168-8577-442bbcd893f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://static.sfdict.com/audio/C07/C0702600.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "display.Audio(url=\"https://static.sfdict.com/audio/C07/C0702600.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rmsu5BXmbRa"
   },
   "source": [
    "### load checkpoint and resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "cHAq9xgumbRb",
    "outputId": "caf37a84-f847-4ceb-8bef-6a40c32c6456"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0001.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0002.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0003.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0004.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0005.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0006.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0007.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0008.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0009.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0010.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0011.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0012.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0013.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0014.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0015.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0016.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0017.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0018.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_checkpoint_0019.pth.tar',\n",
       " 'FF_diff_test_cosine_separate_num_neg_v2_stats.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL = False # CHANGE THIS \n",
    "cosine = True # CHANGE THIS \n",
    " \n",
    "if LOCAL: \n",
    "    checkpoint_folder = 'checkpoints/'\n",
    "    base_path = 'USPTO_50k_data/clean_rxn_50k_sparse_FPs_numrcts'\n",
    "    if cosine:\n",
    "        cluster_path = 'USPTO_50k_data/50k_allmols_sparse_FP_clusterIndex.bin'\n",
    "        sparseFP_vocab_path = 'USPTO_50k_data/50k_all_mols_sparse_FPs.npz'\n",
    "else: # colab \n",
    "    checkpoint_folder = '/content/gdrive/My Drive/rxn_ebm/checkpoints/' \n",
    "    base_path = '/content/clean_rxn_50k_sparse_FPs_numrcts'\n",
    "    if cosine:\n",
    "        cluster_path = '/content/50k_allmols_sparse_FP_clusterIndex.bin' \n",
    "        sparseFP_vocab_path = '/content/50k_all_mols_sparse_FPs.npz'\n",
    "\n",
    "filenames = [filename for filename in os.listdir(checkpoint_folder) \n",
    "             if 'separate' in filename] # narrow down list \n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4wHy5numbRe"
   },
   "outputs": [],
   "source": [
    "opt = 'Adam' # needed to fix bug in name of optimizer when saving checkpoint\n",
    "stats_filename = 'FF_diff_test_cosine_separate_num_neg_v2_stats.pkl' # copy & paste from list above \n",
    "# filenames must end w/ stats.pkl\n",
    "\n",
    "curr_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "stats = torch.load(checkpoint_folder + stats_filename, \n",
    "          map_location=torch.device('cpu'))\n",
    "stats['trainargs']['base_path'] = base_path\n",
    "stats['trainargs']['checkpoint_path'] = checkpoint_folder\n",
    "stats['trainargs']['cluster_path'] = cluster_path\n",
    "stats['trainargs']['sparseFP_vocab_path'] = sparseFP_vocab_path\n",
    "\n",
    "if opt == 'Adam':\n",
    "    stats['trainargs']['optimizer'] = torch.optim.Adam # fix bug in name of optimizer when saving checkpoint\n",
    "\n",
    "stats['best_epoch'] = stats['mean_val_loss'].index(stats['min_val_loss']) + 1  # 1-index \n",
    "stats['trainargs']['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "try: \n",
    "    checkpoint_filename = stats_filename[:-9]+'checkpoint_{}.pth.tar'.format(str(stats['best_epoch']).zfill(4)) \n",
    "    checkpoint = torch.load(checkpoint_folder + checkpoint_filename,\n",
    "          map_location=torch.device(curr_device))\n",
    "\n",
    "    model = FF_ebm(stats['trainargs'])\n",
    "    optimizer = stats['trainargs']['optimizer'](model.parameters(), lr=stats['trainargs']['learning_rate'])\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    if torch.cuda.is_available(): # move optimizer tensors to gpu  https://github.com/pytorch/pytorch/issues/2830\n",
    "      for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.cuda()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('best_epoch: {}'.format(stats['best_epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jR3qeCT8mbRh"
   },
   "outputs": [],
   "source": [
    "# trainargs = {'activation': 'ReLU',\n",
    "#  'batch_size': 512,\n",
    "#  'checkpoint': True,\n",
    "#  'checkpoint_path': checkpoint_folder,\n",
    "#  'device': curr_device,\n",
    "#  'cluster_path': cluster_path,\n",
    "#  'sparseFP_vocab_path': sparseFP_vocab_path,\n",
    "#  'dropout': 0.1,\n",
    "#  'early_stop': True,\n",
    "#  'epochs': 50,\n",
    "#  'expt_name': 'cosine_4096_1layer_3neg_rad3_ReLU', # change this if needed\n",
    "#  'fp_radius': 3,\n",
    "#  'fp_type': 'diff',\n",
    "#  'hidden_sizes': [256],\n",
    "#  'learning_rate': 1e-4,\n",
    "#  'min_delta': 1e-4,\n",
    "#  'model': 'FF_diff',\n",
    "#  'model_seed': 1337,\n",
    "#  'num_neg': 5,\n",
    "#  'optimizer': torch.optim.Adam,\n",
    "#  'output_size': 1,\n",
    "#  'base_path': base_path, \n",
    "#  'patience': 3, \n",
    "#  'prodfp_size': 4096,\n",
    "#  'random_seed': 0,\n",
    "#  'rctfp_size': 4096}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UjWSobNmbRj"
   },
   "outputs": [],
   "source": [
    "run = Run(model, stats['trainargs'], optimizer, load_checkpoint=True, load_stats=stats, begin_epoch=stats['best_epoch'])\n",
    "# run.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "t1nRpvJnmbRn",
    "outputId": "e7483004-e373-4abd-8e8e-a6681425ef2d"
   },
   "outputs": [],
   "source": [
    "run.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "AiFMy7gBmbRs",
    "outputId": "bc805cdc-4dfe-4ff6-c973-348764273f01"
   },
   "outputs": [],
   "source": [
    "test_dataset = ReactionDataset(stats['trainargs']['base_path'], 'test', stats['trainargs'])\n",
    "test_loader = DataLoader(test_dataset, 2 * stats['trainargs']['batch_size'], shuffle=False)\n",
    "\n",
    "run.get_topk_acc(test_loader, 1, repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "bZroZKa-mbRu",
    "outputId": "1fa5a72f-f4ad-4885-9505-a4e6615a89dc"
   },
   "outputs": [],
   "source": [
    "test_dataset = ReactionDataset(stats['trainargs']['base_path'], 'test', stats['trainargs'])\n",
    "test_loader = DataLoader(test_dataset, 2 * stats['trainargs']['batch_size'], shuffle=False)\n",
    "\n",
    "scores = run.get_scores(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EhpV5i9AmbR0",
    "outputId": "6fba34d8-b84b-40af-a811-af27bfc27ceb"
   },
   "outputs": [],
   "source": [
    "torch.where(scores[:, 0] == scores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "m7RypmMV2N3I",
    "outputId": "24cffe71-fb0c-40c9-8c3e-0f5e753ac568"
   },
   "outputs": [],
   "source": [
    "print('% of test samples w/ same score assigned to pos_rxn & nearest prod: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 1])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & 2nd nearest prod: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 2])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & nearest rct: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 3])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & 2nd nearest rct: {:.5f}'.format( \n",
    "      len(torch.where(scores[:, 0] == scores[:, 4])[0]) / len(test_dataset) * 100))\n",
    "\n",
    "print('% of test samples w/ same score assigned to pos_rxn & nearest rct & prod (in same sample): {:.5f}'.format( \n",
    "      len(torch.where((scores[:, 0] == scores[:, 4]) & (scores[:, 0] == scores[:, 1]))[0]) / len(test_dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cQ8ewor2mbR3",
    "outputId": "d75b713c-d2c5-4677-fe35-d9ab16100c1d"
   },
   "outputs": [],
   "source": [
    "(torch.where(scores[:, 0] < scores[:, 1])[0].numpy().shape[0], \n",
    "torch.where(scores[:, 0] < scores[:, 2])[0].numpy().shape[0], \n",
    "torch.where(scores[:, 0] < scores[:, 3])[0].numpy().shape[0],\n",
    "torch.where(scores[:, 0] < scores[:, 4])[0].numpy().shape[0])\n",
    "# torch.where(scores[:, 0] < scores[:, 5])[0].numpy().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUlvMO_ZmbR6"
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1) \n",
    "probs = torch.clamp(softmax(scores), min=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "GI_Pb1lDmbR9",
    "outputId": "3e70c88c-07a8-4f87-f01f-a30f346103c6"
   },
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5hR7S_XdmbR_",
    "outputId": "3676cc93-b356-4746-9106-659c99532b91"
   },
   "outputs": [],
   "source": [
    "probs[probs[:, 0].argmin().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NM93yohmbSC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "Permute all MONOcluster + bs 64, num_neg v2, 384 + train cosine sparseFP + FF_ebm .ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
